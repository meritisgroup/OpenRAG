{"id": "2OKdXGSPzX00KOP", "position_in_doc": 1, "document": "tableau_RC.pdf", "text": ".", "doc_id": 0}
{"id": "zhiJ5lEGu0gpXOv", "position_in_doc": 2, "document": "tableau_RC.pdf", "text": "20\b\nTEF, édition 2020 – Insee Références\nRetrouvez le TEF sur www.insee.fr dans la collection « Insee Références »\nC\nomme à l’échelle mondiale, l’évolution \ndes températures moyennes annuelles en \nFrance métropolitaine témoigne d’un réchauf‑\nfement net depuis 1900.. Ce réchauffement \na connu un rythme variable, avec une aug‑\nmentation particulièrement marquée depuis \nles années 1980.. En 2018, la température \nmoyenne annuelle de 13,9 °C a dépassé la \nnormale (référence 1961‑1990) de 2,1 °C, \nplaçant cette année au premier rang des \nannées les plus chaudes observées en France \nmétropolitaine.. En 2017, les émissions mondiales de \nsix gaz à effet de serre (GES) (y com‑\npris UTCATF) couverts initialement par le \nprotocole de Kyoto ont doublé depuis 1970 \net ont augmenté de plus de 40 % depuis \n1990 pour atteindre 53,5 milliards de tonnes \néquivalent CO2 en 2017..", "doc_id": 0}
{"id": "bgDopgOyu8sKRVn", "position_in_doc": 3, "document": "tableau_RC.pdf", "text": "Le CO2 représente \nles trois quarts de ces émissions.. En 2017, les \némissions mondiales de CO2 (hors UTCATF) \natteignent 37,1 milliards de tonnes.. Elles aug‑\nmentent de 1,2 % en un an, à un rythme plus \nsoutenu qu’en 2016 (+ 0,3 %).. Plus de 39 % \nde ces émissions sont liées à la combustion de \ncharbon, contre 31 % pour le pétrole et 18 % \npour le gaz naturel..", "doc_id": 0}
{"id": "6If6z3FNBAhADCE", "position_in_doc": 4, "document": "tableau_RC.pdf", "text": "Note : \névolution du pouvoir de réchauffement global (PRG) ; données 2018 provisoires..", "doc_id": 0}
{"id": "iwoxqrOoGPzZPhb", "position_in_doc": 5, "document": "tableau_RC.pdf", "text": "Source : Citepa, calculs Insee..", "doc_id": 0}
{"id": "k2EeGTxqA6QZ9mZ", "position_in_doc": 6, "document": "tableau_RC.pdf", "text": "Ces émissions de CO2 représentent 65 % des émissions de GES..", "doc_id": 0}
{"id": "zJnlRjAYYuSBAGo", "position_in_doc": 7, "document": "tableau_RC.pdf", "text": "Sources : Banque mondiale, 2019 ; SDES d’après EDGAR, 2018..", "doc_id": 0}
{"id": "fc3C4YiPqruz1ZQ", "position_in_doc": 8, "document": "tableau_RC.pdf", "text": "Écart à la moyenne des températures  \nde la période 1961‑1990\nen degrés celsius (°C)\n– 1,5\n– 1,0\n– 0,5\n0,0\n0,5\n1,0\n1,5\n2,5\n1900 1910 1920 1930 1940 1950 1960 1970 1980 1990 2000 2010\n2,0\nChamp : France métropolitaine..Note : le dernier point affiché correspond à l’année 2018..", "doc_id": 0}
{"id": "9151cwd4jE7kamm", "position_in_doc": 9, "document": "tableau_RC.pdf", "text": "tchèque\n200\n151\n130\n99\n8\n16\nRoumanie\n249\n144\n115\n76\n19\n13\nRoyaume‑Uni\n810\n742\n505\n379\n41\n30\nSlovaquie\n73\n49\n43\n29\n3\n10\nSlovénie\n19\n19\n18\n14\n2\n1\nSuède\n73\n70\n55\n37\n7\n8\nUE\n5 723 5 287\n4 483\n3 368\n439\n377\nNote : hors UTCATF, y c. aviation internationale.. Source : Agence européenne pour l’environnement (extraction base \nEurostat du 12 novembre 2019)..", "doc_id": 0}
{"id": "Teet99doBUzyqrb", "position_in_doc": 10, "document": "tableau_RC.pdf", "text": "Émissions de gaz à effet de serre  \nhors UTCATF par secteur d’activité\nen millions de tonnes équivalent CO2\n1990 (r) 2000 (r) 2005 (r) 2018 (e)\nTransports1\n124\n143\n146\n137\nIndustrie manufacturière\n144\n127\n116\n79\nAgriculture et sylviculture\n93\n94\n89\n86\nRésidentiel, tertiaire,  \ninstitutionnel et commercial\n93\n97\n111\n84\nTransformation de l’énergie2\n78\n71\n74\n46\nTraitement centralisé des déchets3\n15\n19\n19\n14\nTotal hors UTCATF\n548\n552\n555\n445\n1..", "doc_id": 0}
{"id": "gHDTVGorJNdu7P0", "position_in_doc": 11, "document": "tableau_RC.pdf", "text": "Trafic domestique uniquement..", "doc_id": 0}
{"id": "ckKxXD8mTjgDVAd", "position_in_doc": 12, "document": "tableau_RC.pdf", "text": "2..", "doc_id": 0}
{"id": "WHDL1nZUcsffPMi", "position_in_doc": 13, "document": "tableau_RC.pdf", "text": "Y c. l’incinération des déchets avec récupération \nd’énergie..", "doc_id": 0}
{"id": "NcC0to6HKFtebCP", "position_in_doc": 14, "document": "tableau_RC.pdf", "text": "3..", "doc_id": 0}
{"id": "i6Zpo2Opqlp2qmM", "position_in_doc": 15, "document": "tableau_RC.pdf", "text": "Hors incinération des déchets avec récupération d’énergie..", "doc_id": 0}
{"id": "s3ktrT92Hh9yfJP", "position_in_doc": 16, "document": "tableau_RC.pdf", "text": "Champ : France et régions ultra périphériques appartenant à l’UE..", "doc_id": 0}
{"id": "QZfMNGumkwNzbxZ", "position_in_doc": 17, "document": "tableau_RC.pdf", "text": "Note : l’année 1990 est la valeur de référence dans le cadre du protocole de \nKyoto..", "doc_id": 0}
{"id": "pwxcCm86CS5ctPk", "position_in_doc": 18, "document": "tableau_RC.pdf", "text": "Données hors UTCATF et aviation internationale.. Sources : Citepa, rapport Secten 2019 ; ministère de la Transition \nécologique et solidaire.. Émissions de gaz à effet de serre  \nselon l’approche empreinte carbone  \net l’inventaire national\nÉmissions sur le territoire national (y compris les exportations)\n0\n2\n4\n6\n8\n10\n12\nMtCO2 éq.. tCO2 éq./habitant\nÉmissions associées aux importations (hors importations ré-exportées)\nÉmissions intérieures (ménages et activités économiques  intérieures hors exportations)\nEmpreinte carbone par personne\nÉmissions sur le territoire par personne\nEmpreinte carbone\nInventaire national\n412 410 412 370 323 324\n211 284 327 371 408 425\n536 540 538 493 440 425\n10,5\n11,5 11,8 11,5 11,0 11,2\n9,0\n8,9\n8,6\n7,6\n6,6\n6,4\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1995 2000 2005 2010 2015 2018 1995 2000 2005 2010 2015 2018\n14\n0\nChamp : France et régions ultrapériphériques appartenant à l’UE..", "doc_id": 0}
{"id": "DoPJrGXFHeQOZ4P", "position_in_doc": 19, "document": "tableau_RC.pdf", "text": "Avertissement\nSauf mention contraire, les données nationales se réfèrent à la France métropolitaine et aux cinq départements \nd’outre‑mer (sauf mention contraire Mayotte est inclus dans les données de la France).. Les données chiffrées sont parfois arrondies (selon les règles mathématiques)..Le résultat arrondi d’une \ncombinaison de données chiffrées (qui fait intervenir leurs valeurs réelles) peut se trouver légèrement \ndifférent de celui que donnerait la combinaison de leurs valeurs arrondies.. Les comparaisons internationales s’appuient en général sur les données issues d’organismes internationaux \n(Eurostat, ONU, etc.).", "doc_id": 0}
{"id": "DI468tEo8djOMuk", "position_in_doc": 20, "document": "tableau_RC.pdf", "text": "En effet, ces organismes effectuent souvent des \najustements de champ ou de méthode, d’ampleur souvent réduite, afin de produire des données comparables \nd’un pays à l’autre..", "doc_id": 0}
{"id": "eg33C3bpANwAWmV", "position_in_doc": 21, "document": "tableau_RC.pdf", "text": "Sauf précision contraire, les indicateurs relatifs à l’Union européenne (UE) figurant dans cet ouvrage portent \nsur l’UE à 28.. Signes conventionnels utilisés\n/// \t\nAbsence de résultat due à la nature des choses\n…\t\nDonnée non disponible\ne\t\nDonnée estimée\nn.s.. Donnée non significative\np\t\nDonnée provisoire\nr\t\nDonnée révisée par rapport à l’édition précédente\n€\t\nEuro\nk\t\nMillier\nM\t\nMillion\nMd\t\nMilliard.", "doc_id": 0}
{"id": "rnH9Qh9SqFTdskU", "position_in_doc": 1, "document": "chap7-COVID-19.pdf", "text": "PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \n \n \n \nCOVID-19 (INFECTION PAR LE CORONAVIRUS SRAS-CoV-2) \nINFORMATIONS GÉNÉRALES \nDÉFINITION \nLa COVID-19 est une infection virale aiguë des voies respiratoires qui est apparue à la fin de \n2019 et qui a entraîné la déclaration d'une pandémie par l'Organisation mondiale de la Santé en \nmars 2020.. Elle est causée par le coronavirus SRAS-CoV-2, un virus qui possède une capacité \nde mutation et qui a engendré plusieurs variants..", "doc_id": 1}
{"id": "AaQ0WT2KsV1BpvD", "position_in_doc": 2, "document": "chap7-COVID-19.pdf", "text": "TABLEAU CLINIQUE \nMême en présence d’une importante charge virale, un pourcentage significatif des personnes \natteintes de la COVID-19 est asymptomatique..", "doc_id": 1}
{"id": "8aVPWmtdythM5R8", "position_in_doc": 3, "document": "chap7-COVID-19.pdf", "text": ": pneumonie, myocardite, insuffisance rénale aiguë, atteintes neurologiques, etc..", "doc_id": 1}
{"id": "deAXqHvgzKfbi1J", "position_in_doc": 4, "document": "chap7-COVID-19.pdf", "text": "), \net peuvent mener au décès..", "doc_id": 1}
{"id": "7ItofPN0hvkrlX4", "position_in_doc": 5, "document": "chap7-COVID-19.pdf", "text": "Néanmoins, chez les enfants, ces affections \ndemeurent moins fréquentes que chez les adultes.. La grossesse n’augmente pas la susceptibilité à une infection par le SRAS-CoV-2.. Toutefois, en \ncas d’infection, les femmes enceintes sont à plus haut risque de symptômes sévères que les \nfemmes non enceintes en âge de concevoir.. Pour plus d’informations concernant les populations particulières, voir la section Femme enceinte, \nla section Enfants immunosupprimés et la section Enfants souffrant de maladie cardiaque ou \npulmonaire ou nés prématurément et infections respiratoires au chapitre 5.. DURÉE DE LA MALADIE \nLa durée des symptômes varie selon la gravité de la maladie..", "doc_id": 1}
{"id": "aYVY0MnrjSNgGog", "position_in_doc": 6, "document": "chap7-COVID-19.pdf", "text": "Pour la COVID-19 sans \ncomplication, les symptômes s’estompent habituellement en moins de 14 jours alors que pour les \ncas sévères, ceux-ci peuvent durer plus d’un mois..", "doc_id": 1}
{"id": "TjRxjDrV0QUKlSM", "position_in_doc": 7, "document": "chap7-COVID-19.pdf", "text": "MODES DE TRANSMISSION \nLe virus se transmet principalement lors de contacts rapprochés entre les personnes, à moins de \ndeux mètres de distance et durant plus de 15 minutes..", "doc_id": 1}
{"id": "7NrWjgXF7LNFVf5", "position_in_doc": 8, "document": "chap7-COVID-19.pdf", "text": "PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \nJuillet 2024 \n3 \n \n \n \n \nLe virus est présent au niveau: \n \n− \ndes sécrétions respiratoires (nasales, pharyngées, laryngées, bronchiques)..", "doc_id": 1}
{"id": "4GRXJG2r7J8nofk", "position_in_doc": 9, "document": "chap7-COVID-19.pdf", "text": "TRAITEMENT \nSpécifique: \n \n− \nDans la majorité des cas, aucun traitement n'est indiqué contre la COVID-19..", "doc_id": 1}
{"id": "CYxIwVoO06cy3ip", "position_in_doc": 10, "document": "chap7-COVID-19.pdf", "text": "Dans certaines \nsituations (ex..", "doc_id": 1}
{"id": "tddfmxNsGC5CmRg", "position_in_doc": 11, "document": "chap7-COVID-19.pdf", "text": ": COVID-19 sévère, COVID-19 chez une personne à haut risque de \ncomplications), un traitement peut être indiqué..", "doc_id": 1}
{"id": "jNDEXSXRrzAxtip", "position_in_doc": 12, "document": "chap7-COVID-19.pdf", "text": "Compte tenu de l'évolution rapide des lignes \ndirectrices, les différents traitements ne sont pas détaillés ici..", "doc_id": 1}
{"id": "csXtwYtk0nUeHGJ", "position_in_doc": 13, "document": "chap7-COVID-19.pdf", "text": "Pour plus d'informations, les \npersonnes à risque de développer des complications devraient communiquer avec un \nmédecin ou un pharmacien.. De soutien: \n \n− \nRepos \n− \nHydratation \n− \nHygiène nasale..", "doc_id": 1}
{"id": "AoTLaHHnGHqZoSH", "position_in_doc": 14, "document": "chap7-COVID-19.pdf", "text": "− Promotion de la vaccination.. − Recommandation des mesures à mettre en place et communication avec l’infirmier(ère) du \nCLSC au besoin..", "doc_id": 1}
{"id": "eQ0c9J1ToXK1z6K", "position_in_doc": 15, "document": "chap7-COVID-19.pdf", "text": "MESURES DE CONTRÔLE \nCas: \n \n− \nLe diagnostic de COVID-19 seul ne justifie pas le retrait du milieu..", "doc_id": 1}
{"id": "4HeBjNkxmzptVKz", "position_in_doc": 16, "document": "chap7-COVID-19.pdf", "text": "− \nExclure l’enfant selon les critères énoncés à la figure 1 du chapitre 3.. − \nLes recommandations actuelles, en l’absence de fièvre, s’appuient sur la présence de \nsymptômes d’infection respiratoire.. Ainsi, les bonnes pratiques à adopter sont les suivantes : \n• \nEn cas de toux, mal de gorge, rhinorrhée ou congestion nasale: port du masque pendant \ntoute la durée des symptômes..", "doc_id": 1}
{"id": "wkD0lcp60c6Uow8", "position_in_doc": 17, "document": "chap7-COVID-19.pdf", "text": "En présence d’un enfant de moins de 5 ans ou d'un jeune \nà besoins particuliers qui ne peut pas porter le masque et qui est symptomatique, il est \nrecommandé à toute personne qui en prend soin de porter un masque et de procéder à \nune hygiène des mains fréquemment.. PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \nJuillet 2024 \n6 \n \n \n \n \n• \nRespect de la distanciation (lorsque possible).. • \nÉvitement des contacts avec les personnes vulnérables (personnes âgées, \nimmunodéprimées ou atteintes de maladie chronique).. • \nÉvitement des événements sociaux non essentiels..", "doc_id": 1}
{"id": "y1BnlkhNZBint3M", "position_in_doc": 18, "document": "chap7-COVID-19.pdf", "text": "La décision d’élargir à d’autres groupes doit être prise au cas par cas, en \nprenant en considération les interactions avec d’autres groupes lors d’activité ou de \npériodes de la journée..", "doc_id": 1}
{"id": "wewfHQWNspbA26i", "position_in_doc": 19, "document": "chap7-COVID-19.pdf", "text": "o Dans une école primaire: tous les enfants et le personnel du même groupe.. La décision \nd’élargir à d’autres groupes doit être prise au cas par cas, en prenant en considération \nles interactions avec d’autres groupes lors d’activités ou de périodes de la journée..", "doc_id": 1}
{"id": "FPMmL7doynA6Fom", "position_in_doc": 20, "document": "chap7-COVID-19.pdf", "text": "o Dans une école secondaire: les contacts devront être identifiés au cas par cas, en \nfonction des types de contacts, en recherchant les activités qui favorisent la \ntransmission (ex..", "doc_id": 1}
{"id": "1znmeVgiTOoBGcw", "position_in_doc": 21, "document": "chap7-COVID-19.pdf", "text": ": cours de chant ou d’instruments à vent).. − \nRemettre une lettre aux contacts identifiés..", "doc_id": 1}
{"id": "lvrfiyqq5mGbrCk", "position_in_doc": 22, "document": "chap7-COVID-19.pdf", "text": "− \nDistribuer des tests de dépistage antigéniques rapides, si disponibles..", "doc_id": 1}
{"id": "pENat9A8FMeMTjA", "position_in_doc": 23, "document": "chap7-COVID-19.pdf", "text": "− \nEncourager les personnes à risque de complications, les personnes qui vivent avec elles et \nles personnes qui leur donnent des soins à se faire vacciner.. PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \nJuillet 2024 \n7 \n \n \n \n \nMesures d’hygiène et environnement \n \nPictogrammes \nRéférences \n \nChapitre 4, section : Hygiène des mains..", "doc_id": 1}
{"id": "iLkr2HF7tJ7L0TZ", "position_in_doc": 24, "document": "chap7-COVID-19.pdf", "text": "Chapitre 4, section : Nettoyage et désinfection \ndes objets, des surfaces et des locaux.. Annexe 3 Calendrier d’entretien proposé dans les \nservices de garde.. Annexe 4 Calendrier d’entretien proposé dans les \nécoles primaires et secondaires \nChapitre 4, section : Hygiène et étiquette \nrespiratoires..", "doc_id": 1}
{"id": "uduYW7b1625q80V", "position_in_doc": 25, "document": "chap7-COVID-19.pdf", "text": "Chapitre 4, section : Qualité de l'air intérieur..", "doc_id": 1}
{"id": "Ni48L37sNah39jp", "position_in_doc": 1, "document": "Fiche_Covid-19.pdf", "text": "www.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 1 / 7\nCovid-19\nMise à jour de la fiche\n03/2025\nAgent pathogène\nDescriptif de l'agent pathogène\nRéservoir et principales sources d'infection\nViabilité et infectiosité\nDonnées épidémiologiques\nNom : \nSARS-CoV-2\nType d'agent  \nVirus\nGroupe(s) de classement  \n3\nDescriptif de l'agent : \nVirus à ARN linéaire non segmenté et enveloppé de la famille des Coronaviridae, du genre Betacoronavirus.. De très nombreux coronavirus peuvent infecter les\nanimaux.. Chez l'homme, six espèces de coronavirus (CoV) étaient connues avant 2020 : les HCoV saisonniers, le SRAS-CoV et le MERS-CoV..", "doc_id": 2}
{"id": "Zir4LoKf6oHcxGW", "position_in_doc": 2, "document": "Fiche_Covid-19.pdf", "text": "Le septième : SARS-CoV-2, a\némergé dans l’espèce humaine au cours du dernier trimestre de 2019 en Chine..", "doc_id": 2}
{"id": "3IrXBIUqE5BICOu", "position_in_doc": 3, "document": "Fiche_Covid-19.pdf", "text": "Leur enveloppe porte à sa surface des protéines de surface S ( spike) disposées en\nforme de couronne, d’où le préfixe « corona » 1.. La souche historique du SARS-CoV-2 de Wuhan a maintenant quasiment disparue, supplantée successivement par différents variants.. En France le variant Delta,\nplus contagieux (émergé en Inde), a été remplacé depuis fin 2021 par le variant Omicron (sous-lignage BA.1), encore plus transmissible (émergé en Afrique australe)..", "doc_id": 2}
{"id": "t9xuhSdFa9P3hvT", "position_in_doc": 4, "document": "Fiche_Covid-19.pdf", "text": "Depuis 2022, le sous-lignage BA.2 d'Omicron est devenu à son tour majoritaire 2..", "doc_id": 2}
{"id": "0D8lN1y4I6ACiwN", "position_in_doc": 5, "document": "Fiche_Covid-19.pdf", "text": "De nombreux variants de ce sous-lignage continuent d’apparaitre (JNI, KP, XEC…) 3.. Type de réservoir  \nAnimal\nHomme\nLe réservoir initial du virus est probablement animal.. Même si le SARS-CoV-2 est très proche d’un virus détecté chez une chauve-souris, l’animal à l’origine de la\ntransmission à l’homme n'a pas encore été identifié.. L’hypothèse du pangolin, petit mammifère, comme hôte intermédiaire entre la chauve-souris et l’homme, n'a pas\nété confirmée..", "doc_id": 2}
{"id": "Fbn8E2qeG8J0NrZ", "position_in_doc": 6, "document": "Fiche_Covid-19.pdf", "text": "L'homme est également un réservoir avec un nombre important de transmissions interhumaines..Par ailleurs, plusieurs espèces de mammifères peuvent être infectées par le SARS-CoV-2, soit à la suite d’un contact rapproché avec des humains ou des animaux\ninfectés, soit lors d’études expérimentales réalisées au laboratoire : les singes, les félidés (chats, tigres), les lapins, les chiens, les furets, les cervidés.. À ce jour, les visons\nsont les seuls animaux avec une possible transmission à l’homme 4.. Principale(s) source(s) : \nSécrétions des voies aériennes..", "doc_id": 2}
{"id": "uQ6AaThQD0HwfF6", "position_in_doc": 7, "document": "Fiche_Covid-19.pdf", "text": "Le virus peut être détecté dans les selles et, plus rarement, également dans le sang ou les urines.. Vecteur : \nPas de vecteur\nViabilité, résistance physico-chimique : \nLe SARS-CoV-2 peut persister dans l’environnement (surfaces notamment) de quelques heures à quelques jours en fonction du type de support, de l’humidité, de la\ntempérature, de la charge virale initiale, d'une exposition aux UV et des conditions de l’étude (conditions expérimentales ou autour des malades) 5.. Les coronavirus humains peuvent être efficacement inactivés par des procédures de désinfection des surfaces avec des solutions titrant 62-71 % d’éthanol, 0.5 % de\nperoxyde d’hydrogène ou 0,1 % d’hypochlorite de sodium avec un temps de contact de minimum 1 minute.. Globalement, tous les produits virucides selon la norme\nNF EN 14476 sont efficaces sur le SARS-CoV-2 6.. Infectiosité : \nDose infectante inconnue.. La probabilité d’infection dépend de la charge virale de la source, de la voie de transmission et de la réponse immunitaire de la personne exposée.. Concernant la\ncharge virale : lors d’un résultat de RT-PCR positif sur un prélèvement nasopharyngé correctement réalisé (voir rubrique diagnostic), on a pu établir une relation\ninversement proportionnelle entre le Ct (Cycle threshold ou cycle-seuil) qui correspond au nombre de cycles de PCR à partir duquel le signal fluorescent est détecté\npar le thermocycleur et la charge virale : ainsi une valeur de Ct > 33 correspond à un marqueur de faible infectiosité ; inversement, une valeur de Ct < 23 correspond\nà un marqueur de forte infectiosité 7..", "doc_id": 2}
{"id": "kP1FsTcTSbPuQqu", "position_in_doc": 8, "document": "Fiche_Covid-19.pdf", "text": "Par ailleurs, l’infection peut être le résultat d’une brève exposition à une dose concentrée du virus ou d’une exposition prolongée ou répétée à une dose plus faible 8.. Les mutations qui facilitent l’entrée du virus dans les cellules hôtes ou qui accroissent la charge virale des personnes infectées peuvent réduire le temps nécessaire\npour recevoir une dose infectieuse.. www.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 2 / 7\nPopulation générale\nMilieu professionnel\nPathologie\nNom de la maladie\nTransmission\nLa maladie\nDans le monde, 776 618 091 cas de COVID-19 dont 7 071 324 décès ont été rapportés de façon cumulative depuis le début de l’épidémie jusqu’au 13 Octobre 2024 9.. En France, le suivi épidémiologique des infections Covid est organisé par Santé Publique France à partir de plusieurs types de données : passage aux urgences\nhospitalières, consultations chez les médecins généralistes et SOS Médecins, taux d’hospitalisations après passage aux urgences et taux d’hospitalisations en\nréanimation, ainsi que sur le taux de positivité des tests PCR dans les laboratoires.. Ces données sont maintenant rapportées dans le rapport mensuel IRA relatif aux\nInfections respiratoires aigües : bronchiolite, grippe et syndromes grippaux ainsi que Covid 10.. Actuellement 100 % des infections sont liées au variant Omicron   2, 3..", "doc_id": 2}
{"id": "opFlCHDq9r0190J", "position_in_doc": 9, "document": "Fiche_Covid-19.pdf", "text": "Au 13 Octobre 2024, le nombre de cas cumulés d’infections rapportés en France était de 39\nMillions provoquant 168 000 morts..", "doc_id": 2}
{"id": "hW45IP3BuxQWEyR", "position_in_doc": 10, "document": "Fiche_Covid-19.pdf", "text": "Le virus continue de circuler de façon endémique en France et partout dans le monde et on estime qu’il a provoqué en France 3\n600 cas pendant les 4 semaines antérieures au 13 Octobre 2024.. À cette date, la Covid est responsable de 1,1 % des hospitalisations après passage aux urgences, 0,5 %\ndes passages aux urgences, entre 10 et 20 % de taux de positivité au laboratoire et entre 1 et 4 % des actes de SOS médecins 3.. De nombreuses études menées auprès des professionnels de santé exerçant en milieu hospitalier ont mis en évidence un risque accru d’exposition et d’infection au\nSARS-CoV-2 par rapport à la population générale pendant la première vague de l’épidémie..", "doc_id": 2}
{"id": "ICUQQspgw1ZS4RP", "position_in_doc": 11, "document": "Fiche_Covid-19.pdf", "text": "Quelques études ont confirmé la présence de virus infectieux dans les selles mais aucune n’a réussi à prouver de façon\ndéfinitive la transmission par les selles (quelques exemples de cas avec une possible transmission fécale-orale ou par aérosols fécaux rapportés)..", "doc_id": 2}
{"id": "c67pOKvU5o6fxXq", "position_in_doc": 12, "document": "Fiche_Covid-19.pdf", "text": "Le taux de reproduction de base (R0) de la souche historique était évalué entre 2,2 et 6,4.. Cependant la transmissibilité du SARS-CoV-2 varie selon les variants (plus\nimportante pour le Delta et surtout pour les sous-lignages d'Omicron).. Période de contagiosité : \n48h avant le début des symptômes, jusque J5 - J7 pour Omicron, après le début des symptômes..", "doc_id": 2}
{"id": "fxvINfbjL5WoAei", "position_in_doc": 13, "document": "Fiche_Covid-19.pdf", "text": "Incubation : \nÉvaluée à 5 jours en moyenne (de 2 à 14 jours).. Clinique : \nChez l’adulte, la Covid-19 se manifeste par une infection respiratoire aiguë avec une fièvre ou une sensation de fièvre, ou une des manifestations suivantes, de\nsurvenue brutale : asthénie, myalgies, céphalées.. www.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 3 / 7\nPopulations à risque particulier\nImmunité et prévention vaccinale\nAvec les nouveaux variants Omicron qui circulent actuellement, le risque d’hospitalisation est nettement diminué par rapport à la souche historique, l’anosmie est\ndevenue rare, les pharyngites plus fréquentes, tandis que les difficultés respiratoires et le besoin de supplémentation en oxygène nettement moins fréquents..", "doc_id": 2}
{"id": "thBQzuygG5gNa5d", "position_in_doc": 14, "document": "Fiche_Covid-19.pdf", "text": "Le\nrisque de formes graves reste néanmoins présent sur certains terrains vulnérables : une étude récente publiée par EPIPHARE en mai 2024, basée sur le Système\nNational des Données de Santé (SNDS), montre que, malgré une efficacité du rappel et une circulation moins virulente du variant Omicron, le risque de Covid grave\npersiste toujours dans les populations vulnérables, en particulier chez les personnes souffrant de troubles neurologiques 16.. Les formes prolongées ou « COVID long » : au décours d’un épisode aigu, plus de 30 % des patients ont encore des symptômes à 1-2 mois et 15 % à 6-8 mois.. Il peut\ns’agir de symptômes persistants ou de nouveaux symptômes.. Si les plus fréquents sont une fatigue sévère, une dyspnée et des signes neurocognitifs, de nombreux\nautres organes peuvent être atteints 17..", "doc_id": 2}
{"id": "UsGpPsVKAWK2lCY", "position_in_doc": 15, "document": "Fiche_Covid-19.pdf", "text": "Dans un certain nombre de\ncas, évalué à 30 % environ, l’ARN viral a été détecté dans les échantillons respiratoires profonds, alors que la RT-PCR était négative dans les prélèvements oro- ou\nnaso-pharyngés.. Traitement : \n18\n1.. Traitements curatifs :\nTraitements de support : paracétamol, oxygénothérapie, prophylaxie thrombo-embolique chez les patients à risque ou sous O 2 ; dans certains cas,\nantibiothérapie, corticothérapie (dexaméthasone si O 2 requérance) ;\nAntiviraux : Paxlovid® (nirmatrelvir/ritonavir) pour les adultes à risque de forme grave de Covid-19 à administrer dans les 5 premiers jours..", "doc_id": 2}
{"id": "QuURZLMzsOSHT8m", "position_in_doc": 16, "document": "Fiche_Covid-19.pdf", "text": "Le Remdesivir peut être utilisé en milieu hospitalier en deuxième intention en cas de contre-indication formelle à Paxlovid..", "doc_id": 2}
{"id": "wy4gF2IvuFV5Ind", "position_in_doc": 17, "document": "Fiche_Covid-19.pdf", "text": "2. l n’existe plus de traitement préventif possible par les anticorps monoclonaux.. Terrain à risque accru d'acquisition : \nImmunodépression.. Terrain à risque accru de forme grave : \n19, 20\nRôle majeur et prépondérant de l’âge dans la survenue de décès et de formes graves liés à la Covid-19.. 2\n2\nCas particulier de la grossesse : \nRisque accru de forme grave à partir du 3  trimestre, tout particulièrement en cas d’obésité, d’âge > 35 ans, de diabète.. Risque d’accouchement prématuré, surtout\nen cas de formes sévères.. La transmission materno-fœtale semble exceptionnelle sans impact majeur sur le nouveau-né 21.. À noter que la vaccination est recommandée chez les femmes enceintes dès le premier trimestre de grossesse avec rappel dès 3 mois après la primovaccination.. e\nwww.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 4 / 7\nImmunité naturelle\nPrévention vaccinale\nQue faire en cas d'exposition ?.", "doc_id": 2}
{"id": "cSDBTn5T3Fxu9E7", "position_in_doc": 18, "document": "Fiche_Covid-19.pdf", "text": "R1, R2\nDéfinition d'un sujet exposé\nConduite à tenir immédiate\nEvaluation du risque\nSelon les caractéristiques de la source et le type d'exposition\nSelon les caractéristiques du sujet exposé\nL'infection par le SARS-CoV-2 induit une immunité capable de protéger d'une forme grave de Covid-19 dans les premiers mois qui suivent l’infection mais cette\nimmunité semble diminuer avec le temps, ce qui expose à des ré-infections, notamment avec des variants différents tel Omicron.. Vaccin disponible  \noui\nAu 15 Octobre 2024, une injection de vaccin est recommandée pour les personnes à risque de forme grave et les professionnels de santé..", "doc_id": 2}
{"id": "zHLB7bhUUYNxiO4", "position_in_doc": 19, "document": "Fiche_Covid-19.pdf", "text": "La formulation de ce vaccin a été\nadaptée au variant JN.1 du virus..", "doc_id": 2}
{"id": "6fSJMs7wFgNl7Zs", "position_in_doc": 20, "document": "Fiche_Covid-19.pdf", "text": "Il existe en forme adulte, pédiatrique (5-11 ans et 6 mois - 4 ans) :\nComirnaty JN.1 adulte utilisé chez les personnes de 12 ans et plus ;\nComirnaty JN.1 pédiatrique pour les enfants de 5 à 11 ans ;\nComirnaty JN.1 pour les enfants de 6 mois à 4 ans.. Le vaccin est injecté par voie intramusculaire.. Une surveillance de 15 minutes après l'injection est recommandée pour certains publics fragiles.. Pour plus d’informations, consulter : Vaccination info service 1..", "doc_id": 2}
{"id": "s4QzxTEEaeJA083", "position_in_doc": 21, "document": "Fiche_Covid-19.pdf", "text": "1https://professionnels.vaccination-info-service.fr/Maladies-et-leurs-vaccins/COVID-19\nImmunite vaccinale : \nL'efficacité vaccinale (EV) du rappel vaccinal contre les formes symptomatiques persiste, malgré les variations du virus circulant, ce qui justifie de renouveler les\nrappels chez les personnes à risque (âge élevé, mucoviscidose, cancer du poumon actif, dialyse chronique, maladies psychologiques et neuro dégénératives (plus\nqu’avec les autres variants) et transplantés d’organes)..", "doc_id": 2}
{"id": "633TDgu7lqwEDgx", "position_in_doc": 22, "document": "Fiche_Covid-19.pdf", "text": "Les EV contre les formes graves sont excellentes.. Personne ayant eu un contact direct avec un cas confirmé, en face à face, à moins de 2 mètres.. Principales professions concernées : \nProfessionnels ayant des contacts rapprochés avec des personnes infectées par le SARS-CoV-2 (professions de santé, médico-sociales ou en contact étroit avec le\npublic).. Rappeler l'importance des mesures d'hygiène, notamment en collectivité : port du masque, désinfection des mains, nettoyage des surfaces et des objets R2..", "doc_id": 2}
{"id": "GUMPtidKVgYAXgS", "position_in_doc": 23, "document": "Fiche_Covid-19.pdf", "text": "En milieu de soin, s'assurer du respect des précautions complémentaires respiratoires 22.. Définition de cas :\nCas possible : toute personne, ayant ou non été en contact à risque (voir rubrique sujet exposé) avec un cas confirmé dans les 14 jours précédant l’apparition des\nsymptômes, présentant des signes cliniques évocateurs de COVID-19.. Cas confirmé : Toute personne, symptomatique ou non, avec un résultat biologique confirmant l’infection par le SARS-CoV-2, par amplification moléculaire (RT-PCR, RT-\nLAMP), par test antigénique naso-pharyngé ou sérologie (dans le cadre d’un diagnostic de rattrapage)..", "doc_id": 2}
{"id": "eQaKvfrQgxZ0EcV", "position_in_doc": 24, "document": "Fiche_Covid-19.pdf", "text": "Type d'exposition : \nProjection de gouttelettes provenant des voies aériennes supérieures, contact avec l’environnement contaminé, sans mesure de protection efficace (masque,\nlunettes, lavage des mains)..", "doc_id": 2}
{"id": "HgAde2Kc6MChU6a", "position_in_doc": 25, "document": "Fiche_Covid-19.pdf", "text": "2https://www.ameli.fr/val-de-marne/assure/sante/themes/covid-19/symptomes-gestes-barrieres-et-recommandations/que-faire-en-cas-de-test-positif-au-covid-19\nEn cas de grossesse : \nSuivi rapproché pour une prise en charge rapide en cas de symptômes ou de test positif.. Le sujet contact doit renforcer les mesures barrières pour protéger son entourage..", "doc_id": 2}
{"id": "0ZYf7SXwlhe6K0j", "position_in_doc": 26, "document": "Fiche_Covid-19.pdf", "text": "Il n’y a pas de mesures particulières pour l’entourage d’un contact.. Déclaration obligatoire  \noui\nDepuis le 1 \n Juillet 2023 la  Covid 19 a été inscrite par décret sur la liste des maladies à déclaration obligatoire.. Le signalement aux autorités sanitaires nationales (DGS, Santé publique France) des cas n’est plus nécessaire..", "doc_id": 2}
{"id": "phEK396n9V5VUGT", "position_in_doc": 27, "document": "Fiche_Covid-19.pdf", "text": "er\nDéclaration d'AT selon les circonstances d'exposition, en particulier en laboratoire..", "doc_id": 2}
{"id": "KF8kUxAjyLReU0c", "position_in_doc": 28, "document": "Fiche_Covid-19.pdf", "text": ":02 62 90 53 20 \n \nSite CNR Virus des infections respiratoires (dont la grippe) : Centre National de Référence des virus des infections\nrespiratoires (dont la grippe) - Institut Pasteur 3\n3https://www.pasteur.fr/fr/sante-publique/tous-cnr/virus-infections-respiratoires-dont-grippe-sars-cov-2?emkfid=EMF-\n22701181460-k--77618669180--s&gad_source=1&gad_campaignid=319181300&gclid=EAIaIQobChMI-\nqaXxKiyjQMVtFJBAh3H8wSBEAAYASAAEgJ6b_D_BwE\nConsultez le site Santé Publique France 4\n4http://invs.santepubliquefrance.fr/Espace-\nprofessionnels/Centres-nationaux-de-\nreference/Liste-et-coordonnees-des-CNR\nR1 │  Covid-19 5..", "doc_id": 2}
{"id": "KZd2cCtK9ggnaWZ", "position_in_doc": 29, "document": "Fiche_Covid-19.pdf", "text": "Coronavirus.. Assurance maladie, 2022..", "doc_id": 2}
{"id": "qh62HWLhO9SBbG0", "position_in_doc": 30, "document": "Fiche_Covid-19.pdf", "text": "5https://www.ameli.fr/assure/covid-19\nR2 │  Avis relatif aux mesures de prévention des infections respiratoires 6 virales (incluant la mise à jour des avis Covid-19) 6..", "doc_id": 2}
{"id": "Jv7mcp9pL8HF1q6", "position_in_doc": 31, "document": "Fiche_Covid-19.pdf", "text": "Haut Conseil de la santé\npublique, 2023..", "doc_id": 2}
{"id": "vYoGGKxKy1rAofE", "position_in_doc": 32, "document": "Fiche_Covid-19.pdf", "text": "6https://www.hcsp.fr/explore.cgi/avisrapportsdomaine?clefr=1343\n1 |  Coronaviridae Study Group of the International Committee on Taxonomy of Viruses - The species Severe acute respiratory syndrom-related coronavirus :\nclassifying 2019-nCoV and naming it SARS-CoV-2..", "doc_id": 2}
{"id": "TZ8gcPXm0hBCPps", "position_in_doc": 33, "document": "Fiche_Covid-19.pdf", "text": "Nat Microbiol..", "doc_id": 2}
{"id": "CS2BFdBcoWZ98lA", "position_in_doc": 34, "document": "Fiche_Covid-19.pdf", "text": "2020 ; 5 (4) : 536-44.. 2 |  Analyse de risque liée aux variants émergents de SARS-CoV-2 7..", "doc_id": 2}
{"id": "w0NtIbO22ME3UnI", "position_in_doc": 35, "document": "Fiche_Covid-19.pdf", "text": "In : Coronavirus : circulation des variants du SARS-CoV-2..", "doc_id": 2}
{"id": "NQc5u47wPUOYy8V", "position_in_doc": 36, "document": "Fiche_Covid-19.pdf", "text": "Santé publique France, 2022..", "doc_id": 2}
{"id": "Jnpq8u7gvJQeRPc", "position_in_doc": 37, "document": "Fiche_Covid-19.pdf", "text": "3 |  Infections respiratoires aiguës (grippe, bronchiolite, COVID-19) 8.. Bulletin du 16 octobre 2024.. Santé publique France, 2024.. 8https://www.santepubliquefrance.fr/maladies-et-traumatismes/maladies-et-infections-respiratoires/grippe/documents/bulletin-national/infections-respiratoires-aigues-\ngrippe-bronchiolite-covid-19-.-bulletin-du-16-octobre-2024\n4 | Fiche technique OIE : Infection par le SARS-CoV-2 chez les animaux 9..", "doc_id": 2}
{"id": "emZipdC4tje3p8y", "position_in_doc": 38, "document": "Fiche_Covid-19.pdf", "text": "Organisation Mondiale de la Santé Animale (OIE), 2022..", "doc_id": 2}
{"id": "T3hOMS8j0FaqlfA", "position_in_doc": 39, "document": "Fiche_Covid-19.pdf", "text": "5 | Marzoli F, Bortolami A, Pezzuto A, Mazzetto E et al..", "doc_id": 2}
{"id": "8e0RqTN14oPWx2x", "position_in_doc": 40, "document": "Fiche_Covid-19.pdf", "text": "- A systematic review of human coronaviruses survival on environmental surfaces..", "doc_id": 2}
{"id": "FovQxYgj04dDivp", "position_in_doc": 41, "document": "Fiche_Covid-19.pdf", "text": "Sci Total Environ..", "doc_id": 2}
{"id": "Qrcq6jg7LgGJBDe", "position_in_doc": 42, "document": "Fiche_Covid-19.pdf", "text": "2021 ; 778 : 146191.. 6 | Kampf G, Todt D, Pfaender S, Steinmann E - Persistence of coronaviruses on inanimate surfaces and their inactivation with biocidal agents..", "doc_id": 2}
{"id": "paL6NI2UGuGmoTt", "position_in_doc": 43, "document": "Fiche_Covid-19.pdf", "text": "J Hosp Infect..", "doc_id": 2}
{"id": "AnaJqmbdN0RBeIZ", "position_in_doc": 44, "document": "Fiche_Covid-19.pdf", "text": "2020 ; 104\n(3) : 246-51..", "doc_id": 2}
{"id": "xtAK5qPyWiTkpeQ", "position_in_doc": 45, "document": "Fiche_Covid-19.pdf", "text": "7 |  Covid-19 : contrôle et prévention de la diffusion des nouveaux variants du virus en milieu de soins 10..", "doc_id": 2}
{"id": "F3Q5wZfH3JW7Of9", "position_in_doc": 46, "document": "Fiche_Covid-19.pdf", "text": "Avis du 3 février 2021.. A systematic review of the\nliterature..", "doc_id": 2}
{"id": "uQlyYJHbHP2VDRg", "position_in_doc": 47, "document": "Fiche_Covid-19.pdf", "text": "Epidemiol Prev..", "doc_id": 2}
{"id": "nMQ7bxHbztspfNg", "position_in_doc": 48, "document": "Fiche_Covid-19.pdf", "text": "2020 ; 44 (5-6 Suppl 2) : 152-59.. 9 |  Who Covid-19 dashboard 11. Who data, 2025..", "doc_id": 2}
{"id": "3cdPflr5G4AFQvS", "position_in_doc": 49, "document": "Fiche_Covid-19.pdf", "text": "10 |  Covid-19 12..", "doc_id": 2}
{"id": "aapvRJTESNPl11n", "position_in_doc": 50, "document": "Fiche_Covid-19.pdf", "text": "Santé publique France, 2025.. 11 |  Stratégie de vaccination contre le Sars-CoV-2 13.. Rôle des facteurs socio-économiques et professionnels dans le risque d’infection et de formes graves de\nCovid-19 et actualisation des recommandations.. Argumentaire du 30 juin 2021.. Haute Autorité de Santé (HAS), 2021..", "doc_id": 2}
{"id": "iYVp5DM1mwKg4UJ", "position_in_doc": 51, "document": "Fiche_Covid-19.pdf", "text": "12 |  Recensement national des cas de COVID-19 chez les professionnels en établissements de santé 14..", "doc_id": 2}
{"id": "LMIlKzaECC4EbSd", "position_in_doc": 52, "document": "Fiche_Covid-19.pdf", "text": "Etudes et enquêtes..", "doc_id": 2}
{"id": "bMZn9bNvuh8o9Fz", "position_in_doc": 53, "document": "Fiche_Covid-19.pdf", "text": "Santé Publique France, 2022..", "doc_id": 2}
{"id": "sXJajx0DQVg0E4I", "position_in_doc": 54, "document": "Fiche_Covid-19.pdf", "text": "13 |  Signalements d’infections à SARS-CoV-2 nosocomiales.. Mars 2020 - Janvier 2022.. Point au 20 janvier 2022 15..", "doc_id": 2}
{"id": "2ao37midnLilAgC", "position_in_doc": 55, "document": "Fiche_Covid-19.pdf", "text": "Santé Publique France, 2022.. 14 |  Coronavirus du syndrome respiratoire aigu sévère 2 (SRAS CoV-2): Substances infectieuses 16.. Fiche Technique Santé-Sécurité : Agents Pathogènes..", "doc_id": 2}
{"id": "BD1X3ikhJvPShHL", "position_in_doc": 56, "document": "Fiche_Covid-19.pdf", "text": "Agence\nde la Santé Publique du Canada, 2023.. 15 | Perron S, Caron S, Lajoie E, Denis G et al..", "doc_id": 2}
{"id": "rK2uACovnZOFxdW", "position_in_doc": 57, "document": "Fiche_Covid-19.pdf", "text": "- COVID-19 : Modes de transmission et efficacité du port de masque de type N95 et du masque médical 17..", "doc_id": 2}
{"id": "tZKr6ge1a01Dmji", "position_in_doc": 58, "document": "Fiche_Covid-19.pdf", "text": "Institut\nnational de santé publique du Québec (INSPQ), 2022..", "doc_id": 2}
{"id": "JC1SmdrSi1aW3um", "position_in_doc": 59, "document": "Fiche_Covid-19.pdf", "text": "16 |  Facteurs de risque d'hospitalisation pour COVID-19 pendant la période Omicron après le rappel vaccinal 18..", "doc_id": 2}
{"id": "29Ica16N9IYtRV8", "position_in_doc": 60, "document": "Fiche_Covid-19.pdf", "text": "EPI-PHARE..", "doc_id": 2}
{"id": "6hmZppvgiR0XYev", "position_in_doc": 61, "document": "Fiche_Covid-19.pdf", "text": "17 | Salmon Céron D, Davido B, Tubiana R, Linard F et al.. - Les formes prolongées de la COVID-19 ou COVID long : formes cliniques et prise en charge..", "doc_id": 2}
{"id": "c7fg4ZRvM4BFSv3", "position_in_doc": 62, "document": "Fiche_Covid-19.pdf", "text": "Méd Mal Infect Form..", "doc_id": 2}
{"id": "qk7JV6Y577ezD3M", "position_in_doc": 63, "document": "Fiche_Covid-19.pdf", "text": "2022 ; 1 (1) : 24-33.. 18 |  Réponse rapide dans le cadre de la COVID-19.. Traitement de la Covid-19 19.. Haute Autorité de Santé (HAS), 2023.. 19https://www.has-sante.fr/upload/docs/application/pdf/2023-06/reco468_fiche_rr_traitement_covid_19_mel.pdf\n19 |  Décret n° 2021-1162 du 8 septembre 2021 pris pour l'application de l'article 20 de la loi n° 2020-473 du 25 avril 2020 de finances rectificative pour\n2020 20..", "doc_id": 2}
{"id": "nCWEH1xFn8kjaJj", "position_in_doc": 64, "document": "Fiche_Covid-19.pdf", "text": "In : Légifrance.. Premier ministre, Ministère chargé du travail, Ministère chargé de la Santé, 2021.. 20https://www.legifrance.gouv.fr/loda/id/JORFTEXT000044030573/2022-03-01/\n20 |  Stratégie de vaccination contre le Sars-Cov-2 21.. Actualisation des facteurs de risque de formes graves de la covid-19 et des recommandations sur la stratégie\nde priorisation des populations à vacciner.. Recommandation médicale.. Haute Autorité de Santé (HAS), 2021..", "doc_id": 2}
{"id": "bYZpY1MTyznHFtn", "position_in_doc": 65, "document": "Fiche_Covid-19.pdf", "text": "21https://www.has-sante.fr/jcms/p_3240117/fr/strategie-de-vaccination-contre-le-sars-cov-2-actualisation-des-facteurs-de-risque-de-formes-graves-de-la-covid-19-et-des-\nrecommandations-sur-la-strategie-de-priorisation-des-populations-a-vacciner\n21 |  Anselem O - Covid 19 et grosssesse..", "doc_id": 2}
{"id": "eCrxznkJs9J7Qsy", "position_in_doc": 66, "document": "Fiche_Covid-19.pdf", "text": "Presse Med Form..", "doc_id": 2}
{"id": "MAzK7pnIUeex4qO", "position_in_doc": 67, "document": "Fiche_Covid-19.pdf", "text": "2021 ; 2 (4) : 343–46..", "doc_id": 2}
{"id": "h6LmlXijSolJktD", "position_in_doc": 68, "document": "Fiche_Covid-19.pdf", "text": "22 |  Guide de prévention de la transmission par voie respiratoire 22..", "doc_id": 2}
{"id": "2AxLZh7kHJBZNPu", "position_in_doc": 69, "document": "Fiche_Covid-19.pdf", "text": "Recommandations.. Société française d'hygiène hospitalière (SF2H), 2024.. 22https://www.sf2h.net/publications/guide-de-prevention-de-la-transmission-par-voie-respiratoire.html.", "doc_id": 2}
{"id": "poWGdGSfA1PMvhD", "position_in_doc": 1, "document": "metadatas.json", "text": "\nExtension de fichier inconnu.", "doc_id": 3}
{"id": "tA75CPe42XYzvpQ", "position_in_doc": 1, "document": "tableau_RC.pdf", "text": ".", "doc_id": 0}
{"id": "oxrJhdvznEv1jaq", "position_in_doc": 2, "document": "tableau_RC.pdf", "text": "20\b\nTEF, édition 2020 – Insee Références\nRetrouvez le TEF sur www.insee.fr dans la collection « Insee Références »\nC\nomme à l’échelle mondiale, l’évolution \ndes températures moyennes annuelles en \nFrance métropolitaine témoigne d’un réchauf‑\nfement net depuis 1900.. Ce réchauffement \na connu un rythme variable, avec une aug‑\nmentation particulièrement marquée depuis \nles années 1980.. En 2018, la température \nmoyenne annuelle de 13,9 °C a dépassé la \nnormale (référence 1961‑1990) de 2,1 °C, \nplaçant cette année au premier rang des \nannées les plus chaudes observées en France \nmétropolitaine.. En 2017, les émissions mondiales de \nsix gaz à effet de serre (GES) (y com‑\npris UTCATF) couverts initialement par le \nprotocole de Kyoto ont doublé depuis 1970 \net ont augmenté de plus de 40 % depuis \n1990 pour atteindre 53,5 milliards de tonnes \néquivalent CO2 en 2017..", "doc_id": 0}
{"id": "YNIWoO48DwTyO6s", "position_in_doc": 3, "document": "tableau_RC.pdf", "text": "Le CO2 représente \nles trois quarts de ces émissions.. En 2017, les \némissions mondiales de CO2 (hors UTCATF) \natteignent 37,1 milliards de tonnes.. Elles aug‑\nmentent de 1,2 % en un an, à un rythme plus \nsoutenu qu’en 2016 (+ 0,3 %).. Plus de 39 % \nde ces émissions sont liées à la combustion de \ncharbon, contre 31 % pour le pétrole et 18 % \npour le gaz naturel..", "doc_id": 0}
{"id": "2nOEp7gqhpxjPHh", "position_in_doc": 4, "document": "tableau_RC.pdf", "text": "Note : \névolution du pouvoir de réchauffement global (PRG) ; données 2018 provisoires..", "doc_id": 0}
{"id": "PflCTkqo7mjAwOG", "position_in_doc": 5, "document": "tableau_RC.pdf", "text": "Source : Citepa, calculs Insee..", "doc_id": 0}
{"id": "Qu8KodxHi5x5hwn", "position_in_doc": 6, "document": "tableau_RC.pdf", "text": "Ces émissions de CO2 représentent 65 % des émissions de GES..", "doc_id": 0}
{"id": "c7Fjk8BtU7veV8F", "position_in_doc": 7, "document": "tableau_RC.pdf", "text": "Sources : Banque mondiale, 2019 ; SDES d’après EDGAR, 2018..", "doc_id": 0}
{"id": "FbET5VzC6xDwpVH", "position_in_doc": 8, "document": "tableau_RC.pdf", "text": "Écart à la moyenne des températures  \nde la période 1961‑1990\nen degrés celsius (°C)\n– 1,5\n– 1,0\n– 0,5\n0,0\n0,5\n1,0\n1,5\n2,5\n1900 1910 1920 1930 1940 1950 1960 1970 1980 1990 2000 2010\n2,0\nChamp : France métropolitaine..Note : le dernier point affiché correspond à l’année 2018..", "doc_id": 0}
{"id": "DZRjynhKdDA57zm", "position_in_doc": 9, "document": "tableau_RC.pdf", "text": "tchèque\n200\n151\n130\n99\n8\n16\nRoumanie\n249\n144\n115\n76\n19\n13\nRoyaume‑Uni\n810\n742\n505\n379\n41\n30\nSlovaquie\n73\n49\n43\n29\n3\n10\nSlovénie\n19\n19\n18\n14\n2\n1\nSuède\n73\n70\n55\n37\n7\n8\nUE\n5 723 5 287\n4 483\n3 368\n439\n377\nNote : hors UTCATF, y c. aviation internationale.. Source : Agence européenne pour l’environnement (extraction base \nEurostat du 12 novembre 2019)..", "doc_id": 0}
{"id": "Qa92S81gordStUb", "position_in_doc": 10, "document": "tableau_RC.pdf", "text": "Émissions de gaz à effet de serre  \nhors UTCATF par secteur d’activité\nen millions de tonnes équivalent CO2\n1990 (r) 2000 (r) 2005 (r) 2018 (e)\nTransports1\n124\n143\n146\n137\nIndustrie manufacturière\n144\n127\n116\n79\nAgriculture et sylviculture\n93\n94\n89\n86\nRésidentiel, tertiaire,  \ninstitutionnel et commercial\n93\n97\n111\n84\nTransformation de l’énergie2\n78\n71\n74\n46\nTraitement centralisé des déchets3\n15\n19\n19\n14\nTotal hors UTCATF\n548\n552\n555\n445\n1..", "doc_id": 0}
{"id": "3aF44MMnB2NPh7d", "position_in_doc": 11, "document": "tableau_RC.pdf", "text": "Trafic domestique uniquement..", "doc_id": 0}
{"id": "CZ5PfpVoQGkzP7z", "position_in_doc": 12, "document": "tableau_RC.pdf", "text": "2..", "doc_id": 0}
{"id": "DddSbbwlZkuTTJS", "position_in_doc": 13, "document": "tableau_RC.pdf", "text": "Y c. l’incinération des déchets avec récupération \nd’énergie..", "doc_id": 0}
{"id": "7VOy2vLv2NdTf60", "position_in_doc": 14, "document": "tableau_RC.pdf", "text": "3..", "doc_id": 0}
{"id": "WY0l3UIK57gzDdN", "position_in_doc": 15, "document": "tableau_RC.pdf", "text": "Hors incinération des déchets avec récupération d’énergie..", "doc_id": 0}
{"id": "2Ttd9CtwvbArOvh", "position_in_doc": 16, "document": "tableau_RC.pdf", "text": "Champ : France et régions ultra périphériques appartenant à l’UE..", "doc_id": 0}
{"id": "ULGWlbgrDiDWqc4", "position_in_doc": 17, "document": "tableau_RC.pdf", "text": "Note : l’année 1990 est la valeur de référence dans le cadre du protocole de \nKyoto..", "doc_id": 0}
{"id": "Fc8L1o2WcOwsevw", "position_in_doc": 18, "document": "tableau_RC.pdf", "text": "Données hors UTCATF et aviation internationale.. Sources : Citepa, rapport Secten 2019 ; ministère de la Transition \nécologique et solidaire.. Émissions de gaz à effet de serre  \nselon l’approche empreinte carbone  \net l’inventaire national\nÉmissions sur le territoire national (y compris les exportations)\n0\n2\n4\n6\n8\n10\n12\nMtCO2 éq.. tCO2 éq./habitant\nÉmissions associées aux importations (hors importations ré-exportées)\nÉmissions intérieures (ménages et activités économiques  intérieures hors exportations)\nEmpreinte carbone par personne\nÉmissions sur le territoire par personne\nEmpreinte carbone\nInventaire national\n412 410 412 370 323 324\n211 284 327 371 408 425\n536 540 538 493 440 425\n10,5\n11,5 11,8 11,5 11,0 11,2\n9,0\n8,9\n8,6\n7,6\n6,6\n6,4\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1995 2000 2005 2010 2015 2018 1995 2000 2005 2010 2015 2018\n14\n0\nChamp : France et régions ultrapériphériques appartenant à l’UE..", "doc_id": 0}
{"id": "0zYsC2UJYhYBdkM", "position_in_doc": 19, "document": "tableau_RC.pdf", "text": "Avertissement\nSauf mention contraire, les données nationales se réfèrent à la France métropolitaine et aux cinq départements \nd’outre‑mer (sauf mention contraire Mayotte est inclus dans les données de la France).. Les données chiffrées sont parfois arrondies (selon les règles mathématiques)..Le résultat arrondi d’une \ncombinaison de données chiffrées (qui fait intervenir leurs valeurs réelles) peut se trouver légèrement \ndifférent de celui que donnerait la combinaison de leurs valeurs arrondies.. Les comparaisons internationales s’appuient en général sur les données issues d’organismes internationaux \n(Eurostat, ONU, etc.).", "doc_id": 0}
{"id": "Zv9Okf1qerXxxnh", "position_in_doc": 20, "document": "tableau_RC.pdf", "text": "En effet, ces organismes effectuent souvent des \najustements de champ ou de méthode, d’ampleur souvent réduite, afin de produire des données comparables \nd’un pays à l’autre..", "doc_id": 0}
{"id": "dSKyGjWMLTvYCiH", "position_in_doc": 21, "document": "tableau_RC.pdf", "text": "Sauf précision contraire, les indicateurs relatifs à l’Union européenne (UE) figurant dans cet ouvrage portent \nsur l’UE à 28.. Signes conventionnels utilisés\n/// \t\nAbsence de résultat due à la nature des choses\n…\t\nDonnée non disponible\ne\t\nDonnée estimée\nn.s.. Donnée non significative\np\t\nDonnée provisoire\nr\t\nDonnée révisée par rapport à l’édition précédente\n€\t\nEuro\nk\t\nMillier\nM\t\nMillion\nMd\t\nMilliard.", "doc_id": 0}
{"id": "Jnbn03T26Thq9pS", "position_in_doc": 1, "document": "chap7-COVID-19.pdf", "text": "PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \n \n \n \nCOVID-19 (INFECTION PAR LE CORONAVIRUS SRAS-CoV-2) \nINFORMATIONS GÉNÉRALES \nDÉFINITION \nLa COVID-19 est une infection virale aiguë des voies respiratoires qui est apparue à la fin de \n2019 et qui a entraîné la déclaration d'une pandémie par l'Organisation mondiale de la Santé en \nmars 2020.. Elle est causée par le coronavirus SRAS-CoV-2, un virus qui possède une capacité \nde mutation et qui a engendré plusieurs variants..", "doc_id": 1}
{"id": "koo21kzCc1Ec66M", "position_in_doc": 2, "document": "chap7-COVID-19.pdf", "text": "TABLEAU CLINIQUE \nMême en présence d’une importante charge virale, un pourcentage significatif des personnes \natteintes de la COVID-19 est asymptomatique..", "doc_id": 1}
{"id": "c3Lligm2m7bfY3A", "position_in_doc": 3, "document": "chap7-COVID-19.pdf", "text": ": pneumonie, myocardite, insuffisance rénale aiguë, atteintes neurologiques, etc..", "doc_id": 1}
{"id": "fL6cRLHe94Mf2K3", "position_in_doc": 4, "document": "chap7-COVID-19.pdf", "text": "), \net peuvent mener au décès..", "doc_id": 1}
{"id": "ly3epCTOUj4Gzt1", "position_in_doc": 5, "document": "chap7-COVID-19.pdf", "text": "Néanmoins, chez les enfants, ces affections \ndemeurent moins fréquentes que chez les adultes.. La grossesse n’augmente pas la susceptibilité à une infection par le SRAS-CoV-2.. Toutefois, en \ncas d’infection, les femmes enceintes sont à plus haut risque de symptômes sévères que les \nfemmes non enceintes en âge de concevoir.. Pour plus d’informations concernant les populations particulières, voir la section Femme enceinte, \nla section Enfants immunosupprimés et la section Enfants souffrant de maladie cardiaque ou \npulmonaire ou nés prématurément et infections respiratoires au chapitre 5.. DURÉE DE LA MALADIE \nLa durée des symptômes varie selon la gravité de la maladie..", "doc_id": 1}
{"id": "4v9VdGqVpaoODGK", "position_in_doc": 6, "document": "chap7-COVID-19.pdf", "text": "Pour la COVID-19 sans \ncomplication, les symptômes s’estompent habituellement en moins de 14 jours alors que pour les \ncas sévères, ceux-ci peuvent durer plus d’un mois..", "doc_id": 1}
{"id": "57XmbDU9M6mc0uW", "position_in_doc": 7, "document": "chap7-COVID-19.pdf", "text": "MODES DE TRANSMISSION \nLe virus se transmet principalement lors de contacts rapprochés entre les personnes, à moins de \ndeux mètres de distance et durant plus de 15 minutes..", "doc_id": 1}
{"id": "hrMqtgwbCxtYQFu", "position_in_doc": 8, "document": "chap7-COVID-19.pdf", "text": "PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \nJuillet 2024 \n3 \n \n \n \n \nLe virus est présent au niveau: \n \n− \ndes sécrétions respiratoires (nasales, pharyngées, laryngées, bronchiques)..", "doc_id": 1}
{"id": "D0J4mbUZKpRl0Kx", "position_in_doc": 9, "document": "chap7-COVID-19.pdf", "text": "TRAITEMENT \nSpécifique: \n \n− \nDans la majorité des cas, aucun traitement n'est indiqué contre la COVID-19..", "doc_id": 1}
{"id": "pJdGribyK93HfLm", "position_in_doc": 10, "document": "chap7-COVID-19.pdf", "text": "Dans certaines \nsituations (ex..", "doc_id": 1}
{"id": "usi6LW2PACuY9On", "position_in_doc": 11, "document": "chap7-COVID-19.pdf", "text": ": COVID-19 sévère, COVID-19 chez une personne à haut risque de \ncomplications), un traitement peut être indiqué..", "doc_id": 1}
{"id": "4AofvrCKQWBGGeI", "position_in_doc": 12, "document": "chap7-COVID-19.pdf", "text": "Compte tenu de l'évolution rapide des lignes \ndirectrices, les différents traitements ne sont pas détaillés ici..", "doc_id": 1}
{"id": "LhaB98w9KWNs0GE", "position_in_doc": 13, "document": "chap7-COVID-19.pdf", "text": "Pour plus d'informations, les \npersonnes à risque de développer des complications devraient communiquer avec un \nmédecin ou un pharmacien.. De soutien: \n \n− \nRepos \n− \nHydratation \n− \nHygiène nasale..", "doc_id": 1}
{"id": "eajCloeiHlKJxzr", "position_in_doc": 14, "document": "chap7-COVID-19.pdf", "text": "− Promotion de la vaccination.. − Recommandation des mesures à mettre en place et communication avec l’infirmier(ère) du \nCLSC au besoin..", "doc_id": 1}
{"id": "S72xcibPY9YXkxI", "position_in_doc": 15, "document": "chap7-COVID-19.pdf", "text": "MESURES DE CONTRÔLE \nCas: \n \n− \nLe diagnostic de COVID-19 seul ne justifie pas le retrait du milieu..", "doc_id": 1}
{"id": "AMMhFPfw4Q0MFP9", "position_in_doc": 16, "document": "chap7-COVID-19.pdf", "text": "− \nExclure l’enfant selon les critères énoncés à la figure 1 du chapitre 3.. − \nLes recommandations actuelles, en l’absence de fièvre, s’appuient sur la présence de \nsymptômes d’infection respiratoire.. Ainsi, les bonnes pratiques à adopter sont les suivantes : \n• \nEn cas de toux, mal de gorge, rhinorrhée ou congestion nasale: port du masque pendant \ntoute la durée des symptômes..", "doc_id": 1}
{"id": "O3UMaYEeMx8Ze3y", "position_in_doc": 17, "document": "chap7-COVID-19.pdf", "text": "En présence d’un enfant de moins de 5 ans ou d'un jeune \nà besoins particuliers qui ne peut pas porter le masque et qui est symptomatique, il est \nrecommandé à toute personne qui en prend soin de porter un masque et de procéder à \nune hygiène des mains fréquemment.. PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \nJuillet 2024 \n6 \n \n \n \n \n• \nRespect de la distanciation (lorsque possible).. • \nÉvitement des contacts avec les personnes vulnérables (personnes âgées, \nimmunodéprimées ou atteintes de maladie chronique).. • \nÉvitement des événements sociaux non essentiels..", "doc_id": 1}
{"id": "iPX7dAAizldtVGI", "position_in_doc": 18, "document": "chap7-COVID-19.pdf", "text": "La décision d’élargir à d’autres groupes doit être prise au cas par cas, en \nprenant en considération les interactions avec d’autres groupes lors d’activité ou de \npériodes de la journée..", "doc_id": 1}
{"id": "3KSsZwC6CYhdzLi", "position_in_doc": 19, "document": "chap7-COVID-19.pdf", "text": "o Dans une école primaire: tous les enfants et le personnel du même groupe.. La décision \nd’élargir à d’autres groupes doit être prise au cas par cas, en prenant en considération \nles interactions avec d’autres groupes lors d’activités ou de périodes de la journée..", "doc_id": 1}
{"id": "qpcHyAB0IsqkpFj", "position_in_doc": 20, "document": "chap7-COVID-19.pdf", "text": "o Dans une école secondaire: les contacts devront être identifiés au cas par cas, en \nfonction des types de contacts, en recherchant les activités qui favorisent la \ntransmission (ex..", "doc_id": 1}
{"id": "vKpEuhUhmLUK5XO", "position_in_doc": 21, "document": "chap7-COVID-19.pdf", "text": ": cours de chant ou d’instruments à vent).. − \nRemettre une lettre aux contacts identifiés..", "doc_id": 1}
{"id": "tjYjl44rpkBgSkC", "position_in_doc": 22, "document": "chap7-COVID-19.pdf", "text": "− \nDistribuer des tests de dépistage antigéniques rapides, si disponibles..", "doc_id": 1}
{"id": "6zu1cYGBhQKTxy4", "position_in_doc": 23, "document": "chap7-COVID-19.pdf", "text": "− \nEncourager les personnes à risque de complications, les personnes qui vivent avec elles et \nles personnes qui leur donnent des soins à se faire vacciner.. PRÉVENTION ET CONTRÔLE DES INFECTIONS DANS LES SERVICES DE GARDE ET ÉCOLES DU \nQUÉBEC – GUIDE D’INTERVENTION) \nCHAPITRE 7 ─ COVID-19 (INFECTION PAR LE CORRONAVIRUS SRAS-COV-2) \nJuillet 2024 \n7 \n \n \n \n \nMesures d’hygiène et environnement \n \nPictogrammes \nRéférences \n \nChapitre 4, section : Hygiène des mains..", "doc_id": 1}
{"id": "dM8d3OxcGGtk2TX", "position_in_doc": 24, "document": "chap7-COVID-19.pdf", "text": "Chapitre 4, section : Nettoyage et désinfection \ndes objets, des surfaces et des locaux.. Annexe 3 Calendrier d’entretien proposé dans les \nservices de garde.. Annexe 4 Calendrier d’entretien proposé dans les \nécoles primaires et secondaires \nChapitre 4, section : Hygiène et étiquette \nrespiratoires..", "doc_id": 1}
{"id": "5E3IdKY2nlEMTIN", "position_in_doc": 25, "document": "chap7-COVID-19.pdf", "text": "Chapitre 4, section : Qualité de l'air intérieur..", "doc_id": 1}
{"id": "WJ7N96Lk7qlnVn0", "position_in_doc": 1, "document": "Fiche_Covid-19.pdf", "text": "www.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 1 / 7\nCovid-19\nMise à jour de la fiche\n03/2025\nAgent pathogène\nDescriptif de l'agent pathogène\nRéservoir et principales sources d'infection\nViabilité et infectiosité\nDonnées épidémiologiques\nNom : \nSARS-CoV-2\nType d'agent  \nVirus\nGroupe(s) de classement  \n3\nDescriptif de l'agent : \nVirus à ARN linéaire non segmenté et enveloppé de la famille des Coronaviridae, du genre Betacoronavirus.. De très nombreux coronavirus peuvent infecter les\nanimaux.. Chez l'homme, six espèces de coronavirus (CoV) étaient connues avant 2020 : les HCoV saisonniers, le SRAS-CoV et le MERS-CoV..", "doc_id": 2}
{"id": "ECHpHid4gEQ2HmP", "position_in_doc": 2, "document": "Fiche_Covid-19.pdf", "text": "Le septième : SARS-CoV-2, a\némergé dans l’espèce humaine au cours du dernier trimestre de 2019 en Chine..", "doc_id": 2}
{"id": "y2eXzg5QFjLdfNM", "position_in_doc": 3, "document": "Fiche_Covid-19.pdf", "text": "Leur enveloppe porte à sa surface des protéines de surface S ( spike) disposées en\nforme de couronne, d’où le préfixe « corona » 1.. La souche historique du SARS-CoV-2 de Wuhan a maintenant quasiment disparue, supplantée successivement par différents variants.. En France le variant Delta,\nplus contagieux (émergé en Inde), a été remplacé depuis fin 2021 par le variant Omicron (sous-lignage BA.1), encore plus transmissible (émergé en Afrique australe)..", "doc_id": 2}
{"id": "kHkjFg4NLxTCRHF", "position_in_doc": 4, "document": "Fiche_Covid-19.pdf", "text": "Depuis 2022, le sous-lignage BA.2 d'Omicron est devenu à son tour majoritaire 2..", "doc_id": 2}
{"id": "3AL8pOiAAVZXcKF", "position_in_doc": 5, "document": "Fiche_Covid-19.pdf", "text": "De nombreux variants de ce sous-lignage continuent d’apparaitre (JNI, KP, XEC…) 3.. Type de réservoir  \nAnimal\nHomme\nLe réservoir initial du virus est probablement animal.. Même si le SARS-CoV-2 est très proche d’un virus détecté chez une chauve-souris, l’animal à l’origine de la\ntransmission à l’homme n'a pas encore été identifié.. L’hypothèse du pangolin, petit mammifère, comme hôte intermédiaire entre la chauve-souris et l’homme, n'a pas\nété confirmée..", "doc_id": 2}
{"id": "IgD7iD04DbgiwyI", "position_in_doc": 6, "document": "Fiche_Covid-19.pdf", "text": "L'homme est également un réservoir avec un nombre important de transmissions interhumaines..Par ailleurs, plusieurs espèces de mammifères peuvent être infectées par le SARS-CoV-2, soit à la suite d’un contact rapproché avec des humains ou des animaux\ninfectés, soit lors d’études expérimentales réalisées au laboratoire : les singes, les félidés (chats, tigres), les lapins, les chiens, les furets, les cervidés.. À ce jour, les visons\nsont les seuls animaux avec une possible transmission à l’homme 4.. Principale(s) source(s) : \nSécrétions des voies aériennes..", "doc_id": 2}
{"id": "9WsKfUeFYBKDQdp", "position_in_doc": 7, "document": "Fiche_Covid-19.pdf", "text": "Le virus peut être détecté dans les selles et, plus rarement, également dans le sang ou les urines.. Vecteur : \nPas de vecteur\nViabilité, résistance physico-chimique : \nLe SARS-CoV-2 peut persister dans l’environnement (surfaces notamment) de quelques heures à quelques jours en fonction du type de support, de l’humidité, de la\ntempérature, de la charge virale initiale, d'une exposition aux UV et des conditions de l’étude (conditions expérimentales ou autour des malades) 5.. Les coronavirus humains peuvent être efficacement inactivés par des procédures de désinfection des surfaces avec des solutions titrant 62-71 % d’éthanol, 0.5 % de\nperoxyde d’hydrogène ou 0,1 % d’hypochlorite de sodium avec un temps de contact de minimum 1 minute.. Globalement, tous les produits virucides selon la norme\nNF EN 14476 sont efficaces sur le SARS-CoV-2 6.. Infectiosité : \nDose infectante inconnue.. La probabilité d’infection dépend de la charge virale de la source, de la voie de transmission et de la réponse immunitaire de la personne exposée.. Concernant la\ncharge virale : lors d’un résultat de RT-PCR positif sur un prélèvement nasopharyngé correctement réalisé (voir rubrique diagnostic), on a pu établir une relation\ninversement proportionnelle entre le Ct (Cycle threshold ou cycle-seuil) qui correspond au nombre de cycles de PCR à partir duquel le signal fluorescent est détecté\npar le thermocycleur et la charge virale : ainsi une valeur de Ct > 33 correspond à un marqueur de faible infectiosité ; inversement, une valeur de Ct < 23 correspond\nà un marqueur de forte infectiosité 7..", "doc_id": 2}
{"id": "3XnM7ot2VB27dbL", "position_in_doc": 8, "document": "Fiche_Covid-19.pdf", "text": "Par ailleurs, l’infection peut être le résultat d’une brève exposition à une dose concentrée du virus ou d’une exposition prolongée ou répétée à une dose plus faible 8.. Les mutations qui facilitent l’entrée du virus dans les cellules hôtes ou qui accroissent la charge virale des personnes infectées peuvent réduire le temps nécessaire\npour recevoir une dose infectieuse.. www.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 2 / 7\nPopulation générale\nMilieu professionnel\nPathologie\nNom de la maladie\nTransmission\nLa maladie\nDans le monde, 776 618 091 cas de COVID-19 dont 7 071 324 décès ont été rapportés de façon cumulative depuis le début de l’épidémie jusqu’au 13 Octobre 2024 9.. En France, le suivi épidémiologique des infections Covid est organisé par Santé Publique France à partir de plusieurs types de données : passage aux urgences\nhospitalières, consultations chez les médecins généralistes et SOS Médecins, taux d’hospitalisations après passage aux urgences et taux d’hospitalisations en\nréanimation, ainsi que sur le taux de positivité des tests PCR dans les laboratoires.. Ces données sont maintenant rapportées dans le rapport mensuel IRA relatif aux\nInfections respiratoires aigües : bronchiolite, grippe et syndromes grippaux ainsi que Covid 10.. Actuellement 100 % des infections sont liées au variant Omicron   2, 3..", "doc_id": 2}
{"id": "luZ2C0AG8KA8Tqe", "position_in_doc": 9, "document": "Fiche_Covid-19.pdf", "text": "Au 13 Octobre 2024, le nombre de cas cumulés d’infections rapportés en France était de 39\nMillions provoquant 168 000 morts..", "doc_id": 2}
{"id": "yVcAXMHEGSyKoqR", "position_in_doc": 10, "document": "Fiche_Covid-19.pdf", "text": "Le virus continue de circuler de façon endémique en France et partout dans le monde et on estime qu’il a provoqué en France 3\n600 cas pendant les 4 semaines antérieures au 13 Octobre 2024.. À cette date, la Covid est responsable de 1,1 % des hospitalisations après passage aux urgences, 0,5 %\ndes passages aux urgences, entre 10 et 20 % de taux de positivité au laboratoire et entre 1 et 4 % des actes de SOS médecins 3.. De nombreuses études menées auprès des professionnels de santé exerçant en milieu hospitalier ont mis en évidence un risque accru d’exposition et d’infection au\nSARS-CoV-2 par rapport à la population générale pendant la première vague de l’épidémie..", "doc_id": 2}
{"id": "9h8irkL7zDtFA5Q", "position_in_doc": 11, "document": "Fiche_Covid-19.pdf", "text": "Quelques études ont confirmé la présence de virus infectieux dans les selles mais aucune n’a réussi à prouver de façon\ndéfinitive la transmission par les selles (quelques exemples de cas avec une possible transmission fécale-orale ou par aérosols fécaux rapportés)..", "doc_id": 2}
{"id": "DB8hMf6SkoEL4ZB", "position_in_doc": 12, "document": "Fiche_Covid-19.pdf", "text": "Le taux de reproduction de base (R0) de la souche historique était évalué entre 2,2 et 6,4.. Cependant la transmissibilité du SARS-CoV-2 varie selon les variants (plus\nimportante pour le Delta et surtout pour les sous-lignages d'Omicron).. Période de contagiosité : \n48h avant le début des symptômes, jusque J5 - J7 pour Omicron, après le début des symptômes..", "doc_id": 2}
{"id": "NzxBgMnhPuVb3I9", "position_in_doc": 13, "document": "Fiche_Covid-19.pdf", "text": "Incubation : \nÉvaluée à 5 jours en moyenne (de 2 à 14 jours).. Clinique : \nChez l’adulte, la Covid-19 se manifeste par une infection respiratoire aiguë avec une fièvre ou une sensation de fièvre, ou une des manifestations suivantes, de\nsurvenue brutale : asthénie, myalgies, céphalées.. www.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 3 / 7\nPopulations à risque particulier\nImmunité et prévention vaccinale\nAvec les nouveaux variants Omicron qui circulent actuellement, le risque d’hospitalisation est nettement diminué par rapport à la souche historique, l’anosmie est\ndevenue rare, les pharyngites plus fréquentes, tandis que les difficultés respiratoires et le besoin de supplémentation en oxygène nettement moins fréquents..", "doc_id": 2}
{"id": "9YT11Ga1E0tKrUz", "position_in_doc": 14, "document": "Fiche_Covid-19.pdf", "text": "Le\nrisque de formes graves reste néanmoins présent sur certains terrains vulnérables : une étude récente publiée par EPIPHARE en mai 2024, basée sur le Système\nNational des Données de Santé (SNDS), montre que, malgré une efficacité du rappel et une circulation moins virulente du variant Omicron, le risque de Covid grave\npersiste toujours dans les populations vulnérables, en particulier chez les personnes souffrant de troubles neurologiques 16.. Les formes prolongées ou « COVID long » : au décours d’un épisode aigu, plus de 30 % des patients ont encore des symptômes à 1-2 mois et 15 % à 6-8 mois.. Il peut\ns’agir de symptômes persistants ou de nouveaux symptômes.. Si les plus fréquents sont une fatigue sévère, une dyspnée et des signes neurocognitifs, de nombreux\nautres organes peuvent être atteints 17..", "doc_id": 2}
{"id": "iBhPjUQ10ApQMJo", "position_in_doc": 15, "document": "Fiche_Covid-19.pdf", "text": "Dans un certain nombre de\ncas, évalué à 30 % environ, l’ARN viral a été détecté dans les échantillons respiratoires profonds, alors que la RT-PCR était négative dans les prélèvements oro- ou\nnaso-pharyngés.. Traitement : \n18\n1.. Traitements curatifs :\nTraitements de support : paracétamol, oxygénothérapie, prophylaxie thrombo-embolique chez les patients à risque ou sous O 2 ; dans certains cas,\nantibiothérapie, corticothérapie (dexaméthasone si O 2 requérance) ;\nAntiviraux : Paxlovid® (nirmatrelvir/ritonavir) pour les adultes à risque de forme grave de Covid-19 à administrer dans les 5 premiers jours..", "doc_id": 2}
{"id": "okN0tgiaMQ4WcLH", "position_in_doc": 16, "document": "Fiche_Covid-19.pdf", "text": "Le Remdesivir peut être utilisé en milieu hospitalier en deuxième intention en cas de contre-indication formelle à Paxlovid..", "doc_id": 2}
{"id": "iBQx97gtej4vHeh", "position_in_doc": 17, "document": "Fiche_Covid-19.pdf", "text": "2. l n’existe plus de traitement préventif possible par les anticorps monoclonaux.. Terrain à risque accru d'acquisition : \nImmunodépression.. Terrain à risque accru de forme grave : \n19, 20\nRôle majeur et prépondérant de l’âge dans la survenue de décès et de formes graves liés à la Covid-19.. 2\n2\nCas particulier de la grossesse : \nRisque accru de forme grave à partir du 3  trimestre, tout particulièrement en cas d’obésité, d’âge > 35 ans, de diabète.. Risque d’accouchement prématuré, surtout\nen cas de formes sévères.. La transmission materno-fœtale semble exceptionnelle sans impact majeur sur le nouveau-né 21.. À noter que la vaccination est recommandée chez les femmes enceintes dès le premier trimestre de grossesse avec rappel dès 3 mois après la primovaccination.. e\nwww.inrs.fr/eficatt\nEFICATT - Fiche FicheCAT générée\nPage 4 / 7\nImmunité naturelle\nPrévention vaccinale\nQue faire en cas d'exposition ?.", "doc_id": 2}
{"id": "DQM5y2QhzRgWQ22", "position_in_doc": 18, "document": "Fiche_Covid-19.pdf", "text": "R1, R2\nDéfinition d'un sujet exposé\nConduite à tenir immédiate\nEvaluation du risque\nSelon les caractéristiques de la source et le type d'exposition\nSelon les caractéristiques du sujet exposé\nL'infection par le SARS-CoV-2 induit une immunité capable de protéger d'une forme grave de Covid-19 dans les premiers mois qui suivent l’infection mais cette\nimmunité semble diminuer avec le temps, ce qui expose à des ré-infections, notamment avec des variants différents tel Omicron.. Vaccin disponible  \noui\nAu 15 Octobre 2024, une injection de vaccin est recommandée pour les personnes à risque de forme grave et les professionnels de santé..", "doc_id": 2}
{"id": "vszi6gHKIUcfzui", "position_in_doc": 19, "document": "Fiche_Covid-19.pdf", "text": "La formulation de ce vaccin a été\nadaptée au variant JN.1 du virus..", "doc_id": 2}
{"id": "8gdtYMfVbAd0lcZ", "position_in_doc": 20, "document": "Fiche_Covid-19.pdf", "text": "Il existe en forme adulte, pédiatrique (5-11 ans et 6 mois - 4 ans) :\nComirnaty JN.1 adulte utilisé chez les personnes de 12 ans et plus ;\nComirnaty JN.1 pédiatrique pour les enfants de 5 à 11 ans ;\nComirnaty JN.1 pour les enfants de 6 mois à 4 ans.. Le vaccin est injecté par voie intramusculaire.. Une surveillance de 15 minutes après l'injection est recommandée pour certains publics fragiles.. Pour plus d’informations, consulter : Vaccination info service 1..", "doc_id": 2}
{"id": "229Wg8gA9n6pfFg", "position_in_doc": 21, "document": "Fiche_Covid-19.pdf", "text": "1https://professionnels.vaccination-info-service.fr/Maladies-et-leurs-vaccins/COVID-19\nImmunite vaccinale : \nL'efficacité vaccinale (EV) du rappel vaccinal contre les formes symptomatiques persiste, malgré les variations du virus circulant, ce qui justifie de renouveler les\nrappels chez les personnes à risque (âge élevé, mucoviscidose, cancer du poumon actif, dialyse chronique, maladies psychologiques et neuro dégénératives (plus\nqu’avec les autres variants) et transplantés d’organes)..", "doc_id": 2}
{"id": "fX6j4mKhnqZQocA", "position_in_doc": 22, "document": "Fiche_Covid-19.pdf", "text": "Les EV contre les formes graves sont excellentes.. Personne ayant eu un contact direct avec un cas confirmé, en face à face, à moins de 2 mètres.. Principales professions concernées : \nProfessionnels ayant des contacts rapprochés avec des personnes infectées par le SARS-CoV-2 (professions de santé, médico-sociales ou en contact étroit avec le\npublic).. Rappeler l'importance des mesures d'hygiène, notamment en collectivité : port du masque, désinfection des mains, nettoyage des surfaces et des objets R2..", "doc_id": 2}
{"id": "9dvEVXer50VIxdv", "position_in_doc": 23, "document": "Fiche_Covid-19.pdf", "text": "En milieu de soin, s'assurer du respect des précautions complémentaires respiratoires 22.. Définition de cas :\nCas possible : toute personne, ayant ou non été en contact à risque (voir rubrique sujet exposé) avec un cas confirmé dans les 14 jours précédant l’apparition des\nsymptômes, présentant des signes cliniques évocateurs de COVID-19.. Cas confirmé : Toute personne, symptomatique ou non, avec un résultat biologique confirmant l’infection par le SARS-CoV-2, par amplification moléculaire (RT-PCR, RT-\nLAMP), par test antigénique naso-pharyngé ou sérologie (dans le cadre d’un diagnostic de rattrapage)..", "doc_id": 2}
{"id": "vv3NyLnYK06LAM3", "position_in_doc": 24, "document": "Fiche_Covid-19.pdf", "text": "Type d'exposition : \nProjection de gouttelettes provenant des voies aériennes supérieures, contact avec l’environnement contaminé, sans mesure de protection efficace (masque,\nlunettes, lavage des mains)..", "doc_id": 2}
{"id": "jFZFssXsKZYw5kd", "position_in_doc": 25, "document": "Fiche_Covid-19.pdf", "text": "2https://www.ameli.fr/val-de-marne/assure/sante/themes/covid-19/symptomes-gestes-barrieres-et-recommandations/que-faire-en-cas-de-test-positif-au-covid-19\nEn cas de grossesse : \nSuivi rapproché pour une prise en charge rapide en cas de symptômes ou de test positif.. Le sujet contact doit renforcer les mesures barrières pour protéger son entourage..", "doc_id": 2}
{"id": "IRdtWtzBYVL2UM8", "position_in_doc": 26, "document": "Fiche_Covid-19.pdf", "text": "Il n’y a pas de mesures particulières pour l’entourage d’un contact.. Déclaration obligatoire  \noui\nDepuis le 1 \n Juillet 2023 la  Covid 19 a été inscrite par décret sur la liste des maladies à déclaration obligatoire.. Le signalement aux autorités sanitaires nationales (DGS, Santé publique France) des cas n’est plus nécessaire..", "doc_id": 2}
{"id": "HtvR2quMCQHmL6R", "position_in_doc": 27, "document": "Fiche_Covid-19.pdf", "text": "er\nDéclaration d'AT selon les circonstances d'exposition, en particulier en laboratoire..", "doc_id": 2}
{"id": "An6GbPShSjkhskN", "position_in_doc": 28, "document": "Fiche_Covid-19.pdf", "text": ":02 62 90 53 20 \n \nSite CNR Virus des infections respiratoires (dont la grippe) : Centre National de Référence des virus des infections\nrespiratoires (dont la grippe) - Institut Pasteur 3\n3https://www.pasteur.fr/fr/sante-publique/tous-cnr/virus-infections-respiratoires-dont-grippe-sars-cov-2?emkfid=EMF-\n22701181460-k--77618669180--s&gad_source=1&gad_campaignid=319181300&gclid=EAIaIQobChMI-\nqaXxKiyjQMVtFJBAh3H8wSBEAAYASAAEgJ6b_D_BwE\nConsultez le site Santé Publique France 4\n4http://invs.santepubliquefrance.fr/Espace-\nprofessionnels/Centres-nationaux-de-\nreference/Liste-et-coordonnees-des-CNR\nR1 │  Covid-19 5..", "doc_id": 2}
{"id": "27LlWaIgcGDXh63", "position_in_doc": 29, "document": "Fiche_Covid-19.pdf", "text": "Coronavirus.. Assurance maladie, 2022..", "doc_id": 2}
{"id": "SVEC5QuhSsCe1zn", "position_in_doc": 30, "document": "Fiche_Covid-19.pdf", "text": "5https://www.ameli.fr/assure/covid-19\nR2 │  Avis relatif aux mesures de prévention des infections respiratoires 6 virales (incluant la mise à jour des avis Covid-19) 6..", "doc_id": 2}
{"id": "knqQLG6fLsBuChj", "position_in_doc": 31, "document": "Fiche_Covid-19.pdf", "text": "Haut Conseil de la santé\npublique, 2023..", "doc_id": 2}
{"id": "pd8Hnx8cJSvoVD8", "position_in_doc": 32, "document": "Fiche_Covid-19.pdf", "text": "6https://www.hcsp.fr/explore.cgi/avisrapportsdomaine?clefr=1343\n1 |  Coronaviridae Study Group of the International Committee on Taxonomy of Viruses - The species Severe acute respiratory syndrom-related coronavirus :\nclassifying 2019-nCoV and naming it SARS-CoV-2..", "doc_id": 2}
{"id": "ApZ7z9RyX8fP1mw", "position_in_doc": 33, "document": "Fiche_Covid-19.pdf", "text": "Nat Microbiol..", "doc_id": 2}
{"id": "X7jWtHZfZN8IEMR", "position_in_doc": 34, "document": "Fiche_Covid-19.pdf", "text": "2020 ; 5 (4) : 536-44.. 2 |  Analyse de risque liée aux variants émergents de SARS-CoV-2 7..", "doc_id": 2}
{"id": "ex2khiAcWnYyCyR", "position_in_doc": 35, "document": "Fiche_Covid-19.pdf", "text": "In : Coronavirus : circulation des variants du SARS-CoV-2..", "doc_id": 2}
{"id": "ERoFyLZwVVOycVr", "position_in_doc": 36, "document": "Fiche_Covid-19.pdf", "text": "Santé publique France, 2022..", "doc_id": 2}
{"id": "jj0PebQAnPnivg0", "position_in_doc": 37, "document": "Fiche_Covid-19.pdf", "text": "3 |  Infections respiratoires aiguës (grippe, bronchiolite, COVID-19) 8.. Bulletin du 16 octobre 2024.. Santé publique France, 2024.. 8https://www.santepubliquefrance.fr/maladies-et-traumatismes/maladies-et-infections-respiratoires/grippe/documents/bulletin-national/infections-respiratoires-aigues-\ngrippe-bronchiolite-covid-19-.-bulletin-du-16-octobre-2024\n4 | Fiche technique OIE : Infection par le SARS-CoV-2 chez les animaux 9..", "doc_id": 2}
{"id": "1i4uG9atg7HTazL", "position_in_doc": 38, "document": "Fiche_Covid-19.pdf", "text": "Organisation Mondiale de la Santé Animale (OIE), 2022..", "doc_id": 2}
{"id": "9oSHBAVDs9SgkAH", "position_in_doc": 39, "document": "Fiche_Covid-19.pdf", "text": "5 | Marzoli F, Bortolami A, Pezzuto A, Mazzetto E et al..", "doc_id": 2}
{"id": "sBRNnRKL7EjBJuf", "position_in_doc": 40, "document": "Fiche_Covid-19.pdf", "text": "- A systematic review of human coronaviruses survival on environmental surfaces..", "doc_id": 2}
{"id": "NQYWo29267uAVsG", "position_in_doc": 41, "document": "Fiche_Covid-19.pdf", "text": "Sci Total Environ..", "doc_id": 2}
{"id": "ROKu2bAQ9ohUQKK", "position_in_doc": 42, "document": "Fiche_Covid-19.pdf", "text": "2021 ; 778 : 146191.. 6 | Kampf G, Todt D, Pfaender S, Steinmann E - Persistence of coronaviruses on inanimate surfaces and their inactivation with biocidal agents..", "doc_id": 2}
{"id": "dYScfngj0eTga6z", "position_in_doc": 43, "document": "Fiche_Covid-19.pdf", "text": "J Hosp Infect..", "doc_id": 2}
{"id": "XBPYWWIc8WJP6pk", "position_in_doc": 44, "document": "Fiche_Covid-19.pdf", "text": "2020 ; 104\n(3) : 246-51..", "doc_id": 2}
{"id": "0Xtz57Mfk1CTrtV", "position_in_doc": 45, "document": "Fiche_Covid-19.pdf", "text": "7 |  Covid-19 : contrôle et prévention de la diffusion des nouveaux variants du virus en milieu de soins 10..", "doc_id": 2}
{"id": "efXuV94JykGIAX4", "position_in_doc": 46, "document": "Fiche_Covid-19.pdf", "text": "Avis du 3 février 2021.. A systematic review of the\nliterature..", "doc_id": 2}
{"id": "7bX2DYtHfChfiML", "position_in_doc": 47, "document": "Fiche_Covid-19.pdf", "text": "Epidemiol Prev..", "doc_id": 2}
{"id": "uDjGf1E6abS1Vcn", "position_in_doc": 48, "document": "Fiche_Covid-19.pdf", "text": "2020 ; 44 (5-6 Suppl 2) : 152-59.. 9 |  Who Covid-19 dashboard 11. Who data, 2025..", "doc_id": 2}
{"id": "CmDnoCZ9eWgS2UL", "position_in_doc": 49, "document": "Fiche_Covid-19.pdf", "text": "10 |  Covid-19 12..", "doc_id": 2}
{"id": "qlfy74jlIk0s0Fj", "position_in_doc": 50, "document": "Fiche_Covid-19.pdf", "text": "Santé publique France, 2025.. 11 |  Stratégie de vaccination contre le Sars-CoV-2 13.. Rôle des facteurs socio-économiques et professionnels dans le risque d’infection et de formes graves de\nCovid-19 et actualisation des recommandations.. Argumentaire du 30 juin 2021.. Haute Autorité de Santé (HAS), 2021..", "doc_id": 2}
{"id": "6RkKMa4RTWAWIax", "position_in_doc": 51, "document": "Fiche_Covid-19.pdf", "text": "12 |  Recensement national des cas de COVID-19 chez les professionnels en établissements de santé 14..", "doc_id": 2}
{"id": "GpCjzetTALWkxNE", "position_in_doc": 52, "document": "Fiche_Covid-19.pdf", "text": "Etudes et enquêtes..", "doc_id": 2}
{"id": "vrLZiOsjPYRjqBu", "position_in_doc": 53, "document": "Fiche_Covid-19.pdf", "text": "Santé Publique France, 2022..", "doc_id": 2}
{"id": "CORfI4tsYO50pAw", "position_in_doc": 54, "document": "Fiche_Covid-19.pdf", "text": "13 |  Signalements d’infections à SARS-CoV-2 nosocomiales.. Mars 2020 - Janvier 2022.. Point au 20 janvier 2022 15..", "doc_id": 2}
{"id": "vJD4BG5isyZS7Jw", "position_in_doc": 55, "document": "Fiche_Covid-19.pdf", "text": "Santé Publique France, 2022.. 14 |  Coronavirus du syndrome respiratoire aigu sévère 2 (SRAS CoV-2): Substances infectieuses 16.. Fiche Technique Santé-Sécurité : Agents Pathogènes..", "doc_id": 2}
{"id": "gXOa7dB4bpFsvce", "position_in_doc": 56, "document": "Fiche_Covid-19.pdf", "text": "Agence\nde la Santé Publique du Canada, 2023.. 15 | Perron S, Caron S, Lajoie E, Denis G et al..", "doc_id": 2}
{"id": "JNZvPayxZlNOTQr", "position_in_doc": 57, "document": "Fiche_Covid-19.pdf", "text": "- COVID-19 : Modes de transmission et efficacité du port de masque de type N95 et du masque médical 17..", "doc_id": 2}
{"id": "QRyEHYOL6ne5DQG", "position_in_doc": 58, "document": "Fiche_Covid-19.pdf", "text": "Institut\nnational de santé publique du Québec (INSPQ), 2022..", "doc_id": 2}
{"id": "yWYVPcnR2Wrm0xJ", "position_in_doc": 59, "document": "Fiche_Covid-19.pdf", "text": "16 |  Facteurs de risque d'hospitalisation pour COVID-19 pendant la période Omicron après le rappel vaccinal 18..", "doc_id": 2}
{"id": "nzu9yN8mQdUdILl", "position_in_doc": 60, "document": "Fiche_Covid-19.pdf", "text": "EPI-PHARE..", "doc_id": 2}
{"id": "3XVCOp3EPqFJhzj", "position_in_doc": 61, "document": "Fiche_Covid-19.pdf", "text": "17 | Salmon Céron D, Davido B, Tubiana R, Linard F et al.. - Les formes prolongées de la COVID-19 ou COVID long : formes cliniques et prise en charge..", "doc_id": 2}
{"id": "qMV8mj9bP4CBPOP", "position_in_doc": 62, "document": "Fiche_Covid-19.pdf", "text": "Méd Mal Infect Form..", "doc_id": 2}
{"id": "sh7zq2NxCW9lVy9", "position_in_doc": 63, "document": "Fiche_Covid-19.pdf", "text": "2022 ; 1 (1) : 24-33.. 18 |  Réponse rapide dans le cadre de la COVID-19.. Traitement de la Covid-19 19.. Haute Autorité de Santé (HAS), 2023.. 19https://www.has-sante.fr/upload/docs/application/pdf/2023-06/reco468_fiche_rr_traitement_covid_19_mel.pdf\n19 |  Décret n° 2021-1162 du 8 septembre 2021 pris pour l'application de l'article 20 de la loi n° 2020-473 du 25 avril 2020 de finances rectificative pour\n2020 20..", "doc_id": 2}
{"id": "lM305IF1JolJVwe", "position_in_doc": 64, "document": "Fiche_Covid-19.pdf", "text": "In : Légifrance.. Premier ministre, Ministère chargé du travail, Ministère chargé de la Santé, 2021.. 20https://www.legifrance.gouv.fr/loda/id/JORFTEXT000044030573/2022-03-01/\n20 |  Stratégie de vaccination contre le Sars-Cov-2 21.. Actualisation des facteurs de risque de formes graves de la covid-19 et des recommandations sur la stratégie\nde priorisation des populations à vacciner.. Recommandation médicale.. Haute Autorité de Santé (HAS), 2021..", "doc_id": 2}
{"id": "Nop7Q8T7Cosl2yd", "position_in_doc": 65, "document": "Fiche_Covid-19.pdf", "text": "21https://www.has-sante.fr/jcms/p_3240117/fr/strategie-de-vaccination-contre-le-sars-cov-2-actualisation-des-facteurs-de-risque-de-formes-graves-de-la-covid-19-et-des-\nrecommandations-sur-la-strategie-de-priorisation-des-populations-a-vacciner\n21 |  Anselem O - Covid 19 et grosssesse..", "doc_id": 2}
{"id": "L0Pf4THvrxlb2H2", "position_in_doc": 66, "document": "Fiche_Covid-19.pdf", "text": "Presse Med Form..", "doc_id": 2}
{"id": "fbcoLGud5Pxu8sV", "position_in_doc": 67, "document": "Fiche_Covid-19.pdf", "text": "2021 ; 2 (4) : 343–46..", "doc_id": 2}
{"id": "ZHjdVQpM57OU036", "position_in_doc": 68, "document": "Fiche_Covid-19.pdf", "text": "22 |  Guide de prévention de la transmission par voie respiratoire 22..", "doc_id": 2}
{"id": "1bAksI2CdGDNR7v", "position_in_doc": 69, "document": "Fiche_Covid-19.pdf", "text": "Recommandations.. Société française d'hygiène hospitalière (SF2H), 2024.. 22https://www.sf2h.net/publications/guide-de-prevention-de-la-transmission-par-voie-respiratoire.html.", "doc_id": 2}
{"id": "VU4psDxDxUeRh3f", "position_in_doc": 1, "document": "metadatas.json", "text": "\nExtension de fichier inconnu.", "doc_id": 3}
{"id": "dqlrkKXtRjeCuj8", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "doc_id": 0}
{"id": "SQ40wf8IwrMKJFr", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "doc_id": 0}
{"id": "nqdpr6rasOKdfGm", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "doc_id": 0}
{"id": "F5lZnmyxCxbTL2G", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "doc_id": 0}
{"id": "wtEq49HivQpchtX", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "doc_id": 0}
{"id": "PWbnzRW16eV6Ovy", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "doc_id": 0}
{"id": "lZabQMkXrb5klyS", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "doc_id": 0}
{"id": "4jVsbgEmgBwI7aj", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "doc_id": 0}
{"id": "UuxK6yfDnCB7YrQ", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "doc_id": 0}
{"id": "tcphmclAZ04EAed", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "doc_id": 0}
{"id": "sjN8XeJgwuABJTh", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "doc_id": 0}
{"id": "Jjiokjv9Edm2uGf", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "doc_id": 0}
{"id": "N4SuPfyoRzewPe3", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "doc_id": 0}
{"id": "G8T60pYCn8Fo6IH", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "doc_id": 0}
{"id": "6DFy3F2wfF7Hh94", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "doc_id": 0}
{"id": "Y4wAUHP0gxOkvWr", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "doc_id": 0}
{"id": "rvVQcC77i14YP0t", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "doc_id": 0}
{"id": "E1us6nfoBrrD3dK", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "doc_id": 0}
{"id": "7wV7AaTTMOUVOEg", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "doc_id": 0}
{"id": "MHihA9SQgmAhkIj", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "doc_id": 0}
{"id": "VhPDq95qfbqwkXX", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "doc_id": 0}
{"id": "8J8Gc5JUVGVgl5J", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "doc_id": 0}
{"id": "tf2X4nE2qhmz9pb", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "doc_id": 0}
{"id": "Fc0vt74PY28ntWf", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "doc_id": 0}
{"id": "KnAREaKwrCujHOj", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "doc_id": 0}
{"id": "iYcZLf1utvUdSop", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "doc_id": 0}
{"id": "0FXGX3pgu5Lx61e", "position_in_doc": 1, "document": "metadatas.json", "text": "\nExtension de fichier inconnu.", "doc_id": 1}
{"id": "HKqEiKAYNa3NK5c", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "doc_id": 2}
{"id": "CAVBDb2TL3uhhqp", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "doc_id": 0}
{"id": "oZBM4T6iucypN4E", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "doc_id": 0}
{"id": "6i4QP1C717cWye1", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "doc_id": 0}
{"id": "r6E8BrxJiOxpZeS", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "doc_id": 0}
{"id": "MlrRHF0cN4z5OWC", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "doc_id": 0}
{"id": "WfXCtHnTWDuHSaF", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "doc_id": 0}
{"id": "Qre9y8AMm0FCQzo", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "doc_id": 0}
{"id": "xG6PCAUtsLZbVbe", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "doc_id": 0}
{"id": "9hUCewN3YA8hZxE", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "doc_id": 0}
{"id": "Tetf4F1nQC7WlhB", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "doc_id": 0}
{"id": "XwhmHpSIufMPFPF", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "doc_id": 0}
{"id": "kW5gdhJz15XWWeT", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "doc_id": 0}
{"id": "9z1PSbME0qaEjIi", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "doc_id": 0}
{"id": "Nj0kCv0ckrgOd3X", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "doc_id": 0}
{"id": "9OyaGQz9gsklRHq", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "doc_id": 0}
{"id": "8AicoDcpSonCSOj", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "doc_id": 0}
{"id": "gVa31otMc0gJSHx", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "doc_id": 0}
{"id": "djW30tbkV4K50kL", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "doc_id": 0}
{"id": "kHV3vg4iNl3NJc5", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "doc_id": 0}
{"id": "kdsTzZdOZLK6Qf7", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "doc_id": 0}
{"id": "0LSjlasuHJbOKnD", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "doc_id": 0}
{"id": "dj2SsgXjMXa2oCn", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "doc_id": 0}
{"id": "26reVDasmT4SgeJ", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "doc_id": 0}
{"id": "cWT3GldWS4Z9UWX", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "doc_id": 0}
{"id": "z86jIC6kwRIfYld", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "doc_id": 0}
{"id": "I79w8b6SaOdhygN", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "doc_id": 0}
{"id": "rD4SPMFD9g5iwuF", "position_in_doc": 1, "document": "metadatas.json", "text": "\nExtension de fichier inconnu.", "doc_id": 1}
{"id": "yRawK2GlFxQiTwW", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "doc_id": 2}
{"id": "NQZYeVouPuNfqt3", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "doc_id": 0}
{"id": "towDSLM30u6lt7x", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "doc_id": 0}
{"id": "dCNj5MwPGYVRkvU", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "doc_id": 0}
{"id": "5O4nzNK3zHDONJ1", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "doc_id": 0}
{"id": "YmzdL3dpqCCJGST", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "doc_id": 0}
{"id": "WC2n428j2ApwM3g", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "doc_id": 0}
{"id": "SYmoqrF5xxFkD4D", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "doc_id": 0}
{"id": "JSurMfl990VgGkw", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "doc_id": 0}
{"id": "OeVC0nPzsI3e0Z1", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "doc_id": 0}
{"id": "rFWuvyioIkCN4Vw", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "doc_id": 0}
{"id": "ond60zW76cIf5XM", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "doc_id": 0}
{"id": "ppNf7oLotVlJuv1", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "doc_id": 0}
{"id": "vE3IUZaXQny40w9", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "doc_id": 0}
{"id": "0qzQIKE8ZmQg0c4", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "doc_id": 0}
{"id": "xlqgo8N3V9A5PIG", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "doc_id": 0}
{"id": "meZqurIcnAY66VI", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "doc_id": 0}
{"id": "VLDTknkSvZjUL6X", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "doc_id": 0}
{"id": "z4wife7CwmpBMsH", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "doc_id": 0}
{"id": "kmKjMJcbO73dd9A", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "doc_id": 0}
{"id": "fsRm5VUQivyS2jr", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "doc_id": 0}
{"id": "1ZgZiljz3RiM0S6", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "doc_id": 0}
{"id": "e30spADKGCUReBr", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "doc_id": 0}
{"id": "98e2QlXO0lLhdS9", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "doc_id": 0}
{"id": "c3Q2y6jcmqeOQgW", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "doc_id": 0}
{"id": "IA7ktLEDdC0E6xw", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "doc_id": 0}
{"id": "gF1hwGD9b1pGS7d", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "doc_id": 0}
{"id": "LU3FC1Z25rarkRx", "position_in_doc": 1, "document": "metadatas.json", "text": "\nExtension de fichier inconnu.", "doc_id": 1}
{"id": "5HPMY2ZaXyvxl3y", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "doc_id": 2}
{"id": "ZI54M5oKLWDZe6D", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "doc_id": 0}
{"id": "QSIsDvgB1AWYM6m", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "doc_id": 0}
{"id": "4tcA4IFT2LHTPmS", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "doc_id": 0}
{"id": "WwzaHsH1xfXcno3", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "doc_id": 0}
{"id": "cUKiQa4X2fwT9xO", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "doc_id": 0}
{"id": "AxunI102bJFWLLh", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "doc_id": 0}
{"id": "Ypit8RxWg3n804V", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "doc_id": 0}
{"id": "ZV4JZhon6YbGAOd", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "doc_id": 0}
{"id": "KnrygV1LKtmYfRr", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "doc_id": 0}
{"id": "fj3b8tt1TfLL8cy", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "doc_id": 0}
{"id": "9L7tsi3qzft5Iej", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "doc_id": 0}
{"id": "nLrvpIbqC6KlpSD", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "doc_id": 0}
{"id": "YGBEbevbDZRdTVW", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "doc_id": 0}
{"id": "W3Upjer2I5FPSm2", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "doc_id": 0}
{"id": "FNrKNFmvVRUbK1p", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "doc_id": 0}
{"id": "K1MGVUmYJRdHfRE", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "doc_id": 0}
{"id": "ExHDZeShSiCtxYS", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "doc_id": 0}
{"id": "sVv2iDyAqzgNnMn", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "doc_id": 0}
{"id": "5dnwiwGQkTlmq4h", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "doc_id": 0}
{"id": "c2qXjJOOOzyCD9E", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "doc_id": 0}
{"id": "MLoBtQbVX5TRA5J", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "doc_id": 0}
{"id": "o0q9CC3FvA2sfwW", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "doc_id": 0}
{"id": "u9oyH38oibTxeHB", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "doc_id": 0}
{"id": "aCUzJpl7M0Ptt3w", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "doc_id": 0}
{"id": "xXLwSPUHtW8R2zk", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "doc_id": 0}
{"id": "w7pyybvdOG52Jhr", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "doc_id": 0}
{"id": "ZTH8NqQvtpX0HWB", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "doc_id": 1}
{"id": "hnVGajjSkH0h8uO", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "LJXJzLFtEAouAd8", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "sQ8PEvHLQzkaHio", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "109QzcCNsJBPmJE", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "oxEP0KonlJvCEaB", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "mBVnIYtnJDlnFyr", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "PQrV5y3g3F5BTox", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "qMLgtNNjFcP52OP", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "6Gg5E9d8IWAlo7f", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "cCG81jDYzWFoIke", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "aAXqzqstybnFtWl", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "2j6ONssgqBCg5WI", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "xqSSqd4YxFjRUDQ", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "NVyk9W8UsD7yVHb", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "N3DbjuNUiizUaOz", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "hLgJxtuxicB4cpk", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "2wjbmKQS27luOrX", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "PZrxvNAdWsyUPLT", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "TFvhFlz1YBLrdsH", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "5SYqRaWxZYw3SMu", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "rz4fb6VBTVk2Ekj", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "OpK3yTyWUYdaCX0", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "tVuq1VkkuAJbM0G", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "uvVhO7VMAhgorIC", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "28byYX6t5yrR36v", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "oMgm6agCCs7unqv", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "EHapAsC5lRsQjeM", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "RzDXqBnI5wpEy87", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "vxsFauPY24EifXY", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "ofyAy5s626gNNlw", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "Mnreo42swfD6v2G", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "ihyfsE8cFIzqkAS", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "3xyK6QCLUPl7Tvm", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "WxcouQFTM0x3ek9", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "RAJVlF5P0WmdORt", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "OQDpt7z8iRhkMjN", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "WztDf1XHurWeGm9", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "a55aYvzibdj0qaE", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "CrU22rC8w0wGVtK", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "4Mut0kdAoMzXGoD", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "m0iC1EB9u8HoyuN", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "jffLJhNhxkUOzwb", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "ad72ZSTYiRq1y4q", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "u8C0xYJfvJeFSKR", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "gdvEbqWxkXlQiGr", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "xkvPqCnMza3TbrK", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "1WgSHzfzmO8Zy2u", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "sRyPTogQMwMiBiu", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "TaGoWrd49vgGL1j", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "3eHmWs2NQpSXwaa", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "idzDYZEU07EJi8d", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "OiKRqc30jB5dnUg", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "gQoZFp0CqJzdEBB", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "gJX6DXvcb0NN0to", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "Gk5nu2wGNFFNUQj", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "Wn7sWT0vZSShLDK", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "gZkcdZMvGdg5LXo", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "CD4fnz0f26XmO7o", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "WX6Q9wNfKS8c5yF", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "DyTFSwEcgkp8S5A", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "XmaTln2y1p80shr", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "M22B9huAP5UEMIM", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "7KpcWaSS27onBBP", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "NUDalYKrWneRp3b", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "pREWMNhFzVjqJWS", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "tITWYU11owGbZZ4", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "ZK4XCXXNWMtyw6m", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "cAYzqHehoQL7cwH", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "BJEN0B4RfkaDyyS", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "HSy3EVSbGQsjHZ1", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "5nWbBWMWnNJamUh", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "GlwLHxWxtTG743S", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "op54ykN4GXeuA31", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "SFBJwWrGlvMaER3", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "9ZLRzt84Jk9UYo0", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "fo59OZsTCa9U6UW", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "NTwMvNd2kKyHTJ9", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "ivXLUMs1LXHICzk", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "mczG1Q9XfQikfMf", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "D98EF5dD3EhnH6V", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "tEdKOe1EXGK4N4K", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "uz9UMF8uXsejMBQ", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "zSqZdsX4zCe32aX", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "RcM2qsGlRcAHuxh", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "hnHIGcRCTa0Wixr", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "0H9s6wyVhWbRxnL", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "MSkLso0OLESgxdr", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "ct520hzHLZg9W67", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "9LtsBIzc9rdWOvI", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "tJ3C8GzKEo61AGp", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "LQ2dLOYm66OdVlB", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "WbfLidB4rOHhS2X", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "nhjBazYjSFfgAtZ", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "0xmJaEkRxZTpnAy", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "i89F7OiysujGMu6", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "MMQ4A1YKxm17wZf", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "ZLrfjxWwMJSULNW", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "lDc1nt6D0I4qjr1", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "tfye9zzYJRrKLRV", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "3XpbvoOWMNgtfmz", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "jYzFhQ99Gqzripq", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "dV0b4dWxOh9WPCA", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "Wj3YEtK20I0slhS", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "HTzyCejfN7Q6DDc", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "XZzESrJY7yJCrq2", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "5K5wLraJl48lahs", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "nGhf68LivXLu4OF", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "gP7fE03VzTF9cN8", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "UNXuog8TaetI9ky", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "87h7EDysiaCvuDP", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "cOrCNfXhkFzCoHE", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "0EfAHW1VsgHt1jN", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "Q2qD9rlhjquoCuT", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "MtEh47wJuoVX6D3", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "kyohuo5Ehrxp7lY", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "42TQWgzAksI4hTC", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "ie2TimEPg8qgUhR", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "k0GP5I9jxc0heqA", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "MZmFjkVoUnoMQVt", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "JJ8Axvf5thCTEeB", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "y0sQ5vap5B6uXxr", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "1SzoED1L3bzNuia", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "ZHsN9Xs92Fr08lD", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "iqNnTU9XziP6al4", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "QhdcOFQcXIMVbyq", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "qM8jlpafCW16wXm", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "SYbu8kUtFvNhQhx", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "72pO050kH1FELIP", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "UKXb1mvUyYcvkQs", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "w7uZtPs4LpleKcy", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "le965f2oikTsfx2", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "MiATAdnK8XpaynC", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "WdKM7gKZ8ytXZWt", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "4jj2o9ebcEjn1yf", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "dcSyKeIzzFukKcY", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "tVVen5tFtySMdvk", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "XJBc0c0XFnEw4qW", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "dprZW2SagOONmow", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "L2itRUWWKnwCTBz", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "svvRI7mW1Vr1Qre", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "2saeUfzrLqnPYBJ", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "pjGzQhMsu3APkw8", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "mVYVnKSYpe11b8q", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "5hB23VgSVsVxVeG", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "FmkoKRp53LkoqNd", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "ImzquCPvHp43sR7", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "SxeNweJKi5VKv1L", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "8lSsDSG73f8qOft", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "bJWt7d2TPvR2mro", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "wNHo6krxUkZw5KX", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "vhMvHLx83XDb9dX", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "EfDHKx0SBzVhQpC", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "MVIeWzZjOiRApZO", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "OKf7Srz9qKP2u4V", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "LIByJVr9vQViKvI", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "SwKaOgbzp6q8SZs", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "5t2qUCEaKJRSjUJ", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "M7WcqKRQt4Oyg7D", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "84vsreXbXPOQV8S", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "gmAqQz8zPwdJaAU", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "Ugxbo0g5x1BEvw5", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "OldZiXYWif8OjMj", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "rGl2SEdLDDRrSLY", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "ccRnukWIs6cpKML", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "va2oIRy5z2pYDmz", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "GM4wx9Uz9PPIBHW", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "AQZ9S6acs5R4vTk", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "jnVKZE7YYGFXtMd", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "Ey9omSCpnqNWIc1", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "m8GYinBN4UtUfyO", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "VCR6iBDMJ9JAOTj", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "52zN1AL3c4iqwGh", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "HpXDVAFoDg9TVi5", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "RDsRUOMJP3Ob7uz", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "0C4zaqUgZo26xOG", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "rM3GSor61HCnoJS", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "Wl4qaA9ybOieVYZ", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "u6s5bCHWu0SstKD", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "D6WrppmK2bJNeGT", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "oKBQV7sM0eZyNTQ", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "aR4xO90pKXuhFBS", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "UwQhVYqqPe2FHRN", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "6jhLNDTyto1um5X", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "hbx666jPte0iwkp", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "ShvlAxbFu6FNNhe", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "J4AQFaKS9SCPoou", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "pgZuRKKOCYMiO5z", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "BY2Uz23le7cJCDi", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "9CmhEi1yaLDlDU3", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "NtuJkI0470C8c9s", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "O5PxCabbB4kQIHo", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "7UXt0PfiBdlZxVC", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "ZUcXVTGabfOLz3l", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "QWV8CTHvwsowL57", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "ousHOWW2ZmRhGUC", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "66hatQ6UtSZoz1z", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "cgs6ear02BCYoGq", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "oU5UCDeNFEto5QV", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "vIsoqIxhnwcPJGv", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "YdsSBfAyVkntp5U", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "W7GXOqr2vZUlt2S", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "NW1aeEU6NcVJZj0", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "zGw3sQSIiOqv3dA", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "afSSdvai2KxNVdO", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "D39JOyBc5igWeF6", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "30czZ0r65R8RV2T", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "yXX1JtbYvBW4EYA", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "GrMPtp2XEuOrF5w", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "zlr8qJLCq89jfu3", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "Y9Oi1lqXmDW3U5v", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "w1Pk4ntBYLsFK8K", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "uov7u6bjEZL5FXK", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "phi6Qd5yKvimqVA", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "mwsgOxj0jkVIrTD", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "k03pY2BwQdg9f68", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "FLWrFmC41vILkj0", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "z2xobjgksWDi3tv", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "uKMaY5DGzwLCThA", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "1AQbXPcyvPUm7xK", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "qUYaX6DtpWoQ6b9", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "Vrg2kxudJkxHTt2", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "4HWdQ89XjTVhOuI", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "ji6TynclDWA4Woo", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "oUYQ0aYMVX6r2U5", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "871rcP3x8N0NBCF", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "BuvzdT58UXvjnWZ", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "JTA7A2Q9Ffb6WF4", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "nANTjGVjq1YIvig", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "MDDnztwTwD98ubl", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "StW6MwngpJsq806", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "OAxXcK4QusSrW4W", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "PUc2DeLZcEAOpmg", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "ZTLoRUvXk0rWcbq", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "JfgBLBMOJAGgCAR", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "OxEfYG4XwECLSga", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "o8PsQBwmklyVof5", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "EQUObVfzJoOEfKd", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "y6zC6SLgxXnUZb1", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "I7l01lMkSKYlAcT", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "HgFdWp8fmxY0Q2l", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "qig0C2hsZIEWRHO", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "clnLeRyEECEIGtM", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "X864DN2RcuHnZXY", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "c24IRSxaIvU9JTE", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "czrSyyRr0ndASsK", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "7hBYBCSVfuKftit", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "o9PMFoa2ADAgwwi", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "O3hAYbIbE9wCw8O", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "oAS41AwQH5IYW9x", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "74l6BApUgvkyGOT", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "e1BZBIGPikRCStz", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "uipSFcYhvljMfgC", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "lCwDNg6nuVPOioQ", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "cTduF8Ggxk3EIHR", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "JAqskRXQWOjHMQP", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "GakUZvoO2bhfkdz", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "mOXratpweULcA1J", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "5srgQhNCTIY9SYQ", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "H9qzfZVmbvBDaGj", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "wASYGeonfyNtj4l", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "9GlodHpRMjezgtx", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "cuajj3R9RnaTNwO", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "NcuM1n57ONUYFge", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "jAnimMn1UpqzcGa", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "19ogHDWulBXBwMT", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "Lc6evCtF2pIPVon", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "Fd6Unfty9C9evVR", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "TBfdk6bvRORW19W", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "pT4ULFRDd7SRMyY", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "VuY2cYiLyqaibkb", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "KJ5s8gtapgouZ3h", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "MTOHFvvqMS0PC0a", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "KpwS8MUrtqQXcXl", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "ediyntU596YsWBW", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "6qkKnVsOBjW92RI", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "8t9sbNicKXeljzE", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "FmaH5BzChjagorX", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "KibitzUysmlPkcx", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "sR7tYA669wjmIVp", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "ac7d6eCNA9LOj2K", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "Yb65m8fbNRwIZYf", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "uZ8dYesr1l2qNE1", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "zx4iPiV1GQtLQdC", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "qmmiRLNKML5qMhM", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "wqwc9ar7zomvCi0", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "ELXjER82VgT0220", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "ZEhwSQHPEPNpD4S", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "mxMAIk0dg6cWHXF", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "rY85zHs6mDgbesP", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "SXJTg12lTgfVdhS", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "lv5OSxqzMmY2buI", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "ByZHxnm5NuzIPdK", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "JrfflsB5h0n8C8c", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "DX8NXYjYEd6rx5J", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "aJ5wMgZPyj4uT2c", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "PmsLjNCbl8qctXO", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "vwLSFqjIU27IxbU", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "rAlQCWc0utpA2sR", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "FonCz3r29mqL4BD", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "xwJGLEP84VkqLQL", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "K8oVuTD6J80evFg", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "xrI0xA6WYCT09Gd", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "xUUAEgTBCZ9oN1M", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "utTgsYWXfpQ8xXD", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "d6hritt8WlQg6Ql", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "qlyjq3eDmpchDck", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "gCV94LdjRKq7Jmn", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "bGCjhWDrBSy7k1h", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "w3F9NKrDv63R9yE", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "XIi5rIAxTuAyt8F", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "RhMALGQ44OaVjOF", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "QQuzZiEw5lrheac", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "ZQQG86cY1GtwoEN", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "Qn5xMSj9smF3SC0", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "XcXJhe8WwdkzWdY", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "FdrTlfe4jRHrXhd", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "CGipRZYs6pGQeNd", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "gVCAOeCBx3fKvDT", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "9wkU9YtitBWThsb", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "5xy2dFx3npasLIY", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "aczN75Ogk1g04nD", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "QlFbJrgAsLdS6we", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "mcXOFkJh1vxKTfj", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "NLdzyzAhPjBUQRX", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
{"id": "97JYDyZYnavrWHC", "position_in_doc": 1, "document": "RAG_scalabilité.pdf", "text": "RAG Scalability\nClement Hardy, Benoit Joly\nAugust 25, 2025\nAbstract\nThe following study will compare different techniques\non a specific use case that we have made..", "rerank_score": null, "doc_id": 0}
{"id": "kqKave1jZ8KuHEG", "position_in_doc": 2, "document": "RAG_scalabilité.pdf", "text": "The goal is\nto determine the impact of features on a RAG method\nretrieval and post-retrieval part.. 1\nScalability Metrics\n1.1\nMethodology\nWe suppose to have a set of documents D and a set of\nquestions Q on these documents.. For each question\nq ∈Q, we determined the context C(q) needed to\nanswer the question q.. For every splitter s, we denote Cs the set of chunks\nthat represent the set of documents D.For every\nquestion q ∈D, we denote the set of chunks Cs(q)\ncontaining the context C(q).. For every RAG method that retrieves chunks as part\nof context for the LLM, we calculate the minimum\nof chunks retrieved such that the context contains\nall the needed information.. Let us denote by R the\nretrieve function of the RAG method and MR the\nmaximum of retrieved chunks of R The goal is to\nstudy the restriction of R to the set of question Q.\nR\n:\nQ\n→\nCs\nq\n7→\nR(q) ,\nwhere R(q) is an ordered list of chunks..", "rerank_score": null, "doc_id": 0}
{"id": "0IquinFd9Rqnfq8", "position_in_doc": 3, "document": "RAG_scalabilité.pdf", "text": "The absolute goal of a RAG method is for R to\nsatisfy C(q) ⊂R(q) for every user query q while\nminimizing MR..Hence we will run a serie of tests of, such call, best\npractices modifying our RAG method to determine\nthe impact of every feature on the retrieve function R.\n1.2\nMetrics\nFirst, it is important to differentiate the retrive\nfunction R of a RAG method to the actual context\ngiven to the final LLM to generte the user answer..", "rerank_score": null, "doc_id": 0}
{"id": "V3N6Cai5iv0aR3U", "position_in_doc": 4, "document": "RAG_scalabilité.pdf", "text": "This context is created by a fixed portion of the\nretrieved chunks determine by the RAG method and\nthe context length of the LLM used.. Usually, for a\nquery q, only the \"best\" chunks from R(q) is kept,\nHence we can study Rn the retrieval function where\nwe look for the n best chunks (if the method allows\nit) without modifying the studied RAG method and\nthe final context.. For every feature, we calculate the proportion Pn(q)\nof usefull context in the retrieved context Rn(q) of\nevery question q for a fixed sample of n :\nPn(q) = #Cs(q) ∩Rn(q)\n#Rn(q)\nWe also calculate the best and the worst place\nof the elements of #Cs(q) ∩Rn(q) denoted Bs(q)\nand Ws(q) to follow it’s evolutions thought different\nfeatures..", "rerank_score": null, "doc_id": 0}
{"id": "WI2IuLCeUF8qO75", "position_in_doc": 5, "document": "RAG_scalabilité.pdf", "text": "The computation of this metric can be done post\nruns, as we can try distinct p ≤n and get an estimate\nof a good p for a RAG method without considering\ncontext length of the LLM..", "rerank_score": null, "doc_id": 0}
{"id": "ZQXUxS571kRH2ao", "position_in_doc": 6, "document": "RAG_scalabilité.pdf", "text": "1.3\nLimits\nThe first limit is for every methods that can’t recover\nan unlimited number of chunks as threshold technics.. However, as explained, the goal is to analyse the\nimpact of features on the retrieve part and not on the\ncreation of the context.. Indeed, threshold techniques\nare used to minimize the context lenght and then the\ninference time after the retrieve phase.. Another limit is the difficulty to estimate why some\nnon-usefull chunks are retrieved and how close they\nare to the actual retrieve chunks..", "rerank_score": null, "doc_id": 0}
{"id": "1dVqVLlm0agEfbp", "position_in_doc": 7, "document": "RAG_scalabilité.pdf", "text": "This information\nstill remains crucial to avoid hallucination from the\nLLM generating the final answer but won’t be study\nin our first approach..", "rerank_score": null, "doc_id": 0}
{"id": "rQGqgnJ4lUjWbKk", "position_in_doc": 8, "document": "RAG_scalabilité.pdf", "text": "The scalability is limited as the maximal number\nof documents may not be relevant for some more\ndelicate use cases.. 2\nFeatures to evaluate\nWe enumerate all the differents features to tests\n1..", "rerank_score": null, "doc_id": 0}
{"id": "yMdOB7oUrVNgTR6", "position_in_doc": 9, "document": "RAG_scalabilité.pdf", "text": "Data preparation\n2..", "rerank_score": null, "doc_id": 0}
{"id": "DWbUcQxnDwfyzWH", "position_in_doc": 10, "document": "RAG_scalabilité.pdf", "text": "Splitters\n3..", "rerank_score": null, "doc_id": 0}
{"id": "6lkevhOqRqJKPTY", "position_in_doc": 11, "document": "RAG_scalabilité.pdf", "text": "Rerankers\n4.. Query Reformulations\n5..", "rerank_score": null, "doc_id": 0}
{"id": "9eomUDBdO8AymOH", "position_in_doc": 12, "document": "RAG_scalabilité.pdf", "text": "Embeddings\n6.. Metadatas\n2.0.1\nData Preparation\nWe want to estimate the differences between Dp ways\nto prepare the data before splitting it..", "rerank_score": null, "doc_id": 0}
{"id": "2DKJSAKmiWqXKFp", "position_in_doc": 13, "document": "RAG_scalabilité.pdf", "text": "We have 2\ndata preparation to compare :\n1..", "rerank_score": null, "doc_id": 0}
{"id": "xLYvIGa4DPmAR9O", "position_in_doc": 14, "document": "RAG_scalabilité.pdf", "text": "PDFs without prepations\n2.. Markdowns separation using dockling\nRemark..", "rerank_score": null, "doc_id": 0}
{"id": "ymp5bmzozqqO0gj", "position_in_doc": 15, "document": "RAG_scalabilité.pdf", "text": "There are multiple ways to parse the data\nbefore chunking..", "rerank_score": null, "doc_id": 0}
{"id": "zzhDukVbTn1IBcF", "position_in_doc": 16, "document": "RAG_scalabilité.pdf", "text": "Some are not relevant on our use\ncase that we are testing.. 2.0.2\nSplitters\nWe will try S several splitting technics :\n1.. Length splitting\n2.. Semantic Splitting\n3..", "rerank_score": null, "doc_id": 0}
{"id": "3VOmMQjwduMek6g", "position_in_doc": 17, "document": "RAG_scalabilité.pdf", "text": "Recursive Splitting\n4.. Markdown Splitting (only available for the Mark-\ndown data preparation)\n2.1\nMetadatas\nWe will consider the impact of metadatas..", "rerank_score": null, "doc_id": 0}
{"id": "iqceITWaVfaRuEN", "position_in_doc": 18, "document": "RAG_scalabilité.pdf", "text": "We will\ndetermine some kinf of metadatas relevant with our\nfake use case and see the impact of each of them and\neach combination of them.. 2\n2.1.1\nRerankers\nWe will try distincts rerankers separatively.. Best\nwould be to benchmark all rerankers providers as in\nAutoRAG.. unfortunately it won’t be the case in first\ninstance but would be possible to test them as we\nwill keep all chunks retrieved pre-reranking..", "rerank_score": null, "doc_id": 0}
{"id": "EfHEc4LGqZNq52z", "position_in_doc": 19, "document": "RAG_scalabilité.pdf", "text": "Indeed,\nthe reranking phase do not require to re run the\nentire pipeline as it only rerank the chunks already\nordered and retrieved.. We denote by R the number of tested rerankers\n2.1.2\nQuery Reformulation\nWe won’t study naive query reformulation as we con-\nsider our prompt as \"good\" prompts that respect best\npractice of prompt engineering..Moreover, we can\nstudy the multi query expansion..", "rerank_score": null, "doc_id": 0}
{"id": "0331NLZHBgh1c1R", "position_in_doc": 20, "document": "RAG_scalabilité.pdf", "text": "Let us\ndenote by E the number of embeddings..", "rerank_score": null, "doc_id": 0}
{"id": "ZtMTVMsAJSwjMuN", "position_in_doc": 21, "document": "RAG_scalabilité.pdf", "text": "3\nFeatures that won’t affect the\nretrieval study\nWe enumerate all the different features that will not\ninfluence the retrieval but would affect the RAG ac-\ncuracy overall..", "rerank_score": null, "doc_id": 0}
{"id": "sRMXbRUpwmYrTv6", "position_in_doc": 22, "document": "RAG_scalabilité.pdf", "text": "1..", "rerank_score": null, "doc_id": 0}
{"id": "PaLghh8EgKUgWrf", "position_in_doc": 23, "document": "RAG_scalabilité.pdf", "text": "Number of retrieved chunks\n2.. Passage augmenter\n3..", "rerank_score": null, "doc_id": 0}
{"id": "NLY0InIkl9yGVK3", "position_in_doc": 24, "document": "RAG_scalabilité.pdf", "text": "Passage filter (Thresholds)\n4..", "rerank_score": null, "doc_id": 0}
{"id": "7iRFrySpnLU2eOB", "position_in_doc": 25, "document": "RAG_scalabilité.pdf", "text": "Passage Compressor\nAs well we won’t study the server optimizations as\nsharding.. 4\nNumber\nof\nruns\n(without\nmetadatas)\nWe will measure the impact of features on different\ndataset size by adding more documents not relevant\nto our queries sample.. Let us compute all the tests\nwe would :\nT = [(Dp −1) ∗(S −1) ∗E ∗R + S ∗E ∗R] ∗N,\n(2)\ntests to get all information about scalability, where\nN is the number of dataset we are testing.. For Dp = 2, S = 4, E = 3, R = 3, N = 1 we have\nalready 63 tests to run.. We can run all the tests for\nn = 500 and then study the results as if n was smaller\nsince the retrieved phases are not directly impacted\nby n.\n5\nCurves to print\nFor every n we will print Pn(q) and nNDCG(q) as a\nconfidence interval diagrams.. For every feature, we will plot Pn(q) for different\nvalues of n.\nFor every feature we will compute the minimum\nnmin(p) such that Pn(q) = 1 if possible..", "rerank_score": null, "doc_id": 0}
{"id": "OotZsJ4MCLhOqEm", "position_in_doc": 26, "document": "RAG_scalabilité.pdf", "text": "To evaluate rerankers we especially compare the\ndifference between nmin(p) and nDCGp(q) before post-\nretrieval and nmin(p) and nDCGp(q) for the post-\nretrieval part.. 3.", "rerank_score": null, "doc_id": 0}
{"id": "V9q3Cu1W4K01Grd", "position_in_doc": 1, "document": "3002033669_Scaling Intelligence_ The Exponential Growth of AI's Power Needs.PDF", "text": "\nExtension de fichier inconnu.", "rerank_score": null, "doc_id": 1}
