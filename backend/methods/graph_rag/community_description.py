from ...utils.agent import Agent
from .graph_creation import Graph
from ...database.database_class import DataBase
from ...database.rag_classes import (
    MergeEntityDocument,
    MergeEntityOverall,
    Community,
    Entity,
    Relation,
    Tokens,
    CommunityEntity,
    CommunityRelation,
)
from .prompts import PROMPTS
import json
import re
import numpy as np


class CommunityDescription:
    """
    This is the class built to describe communities of a graph and save it in a database
    """

    def __init__(self, agent: Agent, graph: Graph, database: DataBase) -> None:
        """ """
        if graph.communities == []:
            graph.create_communities()

        self.graph = graph
        self.agent = agent
        self.db = database

    def get_context_for_community(
        self, ids: list[int], overall=True, language="EN", community_as_entity=False
    ) -> tuple[str, str]:
        """
        From a list of int representing entities' ids, the prompt and the system prompt to generate the community description
        """
        system_prompt = PROMPTS[language]["summarize_community"]["SYSTEM_PROMPT"]
        query_prompt_template = PROMPTS[language]["summarize_community"]["QUERY_TEMPLATE"]

        if overall:
            entities: list[Entity] = (
                self.db.query(MergeEntityOverall)
                .filter(MergeEntityOverall.id.in_(ids))
                .all()
            )
            doc_name = "all"
            entities_names = [entity.name for entity in entities]
            relations = (
                self.db.query(Relation)
                .filter(
                    Relation.source.in_(entities_names)
                    & Relation.target.in_(entities_names)
                )
                .all()
            )

        elif not overall and not community_as_entity:
            entities = (
                self.db.query(MergeEntityDocument)
                .filter(MergeEntityDocument.id.in_(ids))
                .all()
            )
            doc_name = entities[0].doc_name
            entities_names = [entity.name for entity in entities]
            relations = (
                self.db.query(Relation)
                .filter(
                    Relation.source.in_(entities_names)
                    & Relation.target.in_(entities_names)
                    & Relation.doc_name
                    == doc_name
                )
                .all()
            )

        else:
            entities = (
                self.db.query(CommunityEntity).filter(CommunityEntity.id.in_(ids)).all()
            )
            doc_name = "all"
            entities_names = [entity.name for entity in entities]
            relations = (
                self.db.query(CommunityRelation)
                .filter(
                    CommunityRelation.source.in_(entities_names)
                    & CommunityRelation.target.in_(entities_names)
                )
                .all()
            )

        sorted_entities = sorted(entities, key=lambda x: x.degree, reverse=True)

        context = "Here are provided entities you have to create a consistent title and a consistent description :\n\n"
        for entity in sorted_entities:
            context += f"\t- {entity.name} (retrieved {entity.degree} times in text) : {entity.description}\n\n"

        context += "\nHere are relationships between those entities, retrieved in documents :\n\n"
        for relation in relations:
            context += f"\t- ({relation.source}, {relation.target}) : {relation.description}\n\n"

        context_base = dict(
            language=language,
            list_descriptions=context,
        )
        prompt = query_prompt_template.format(**context_base)

        return prompt, system_prompt

    def process_communities(
        self,
        overall=True,
        language="EN",
        deep_level=1,
        community_as_entity=False,
    ):

        prompts_to_process = []
        system_prompts_to_process = []
        communities_to_process = []
        for community in self.graph.communities:

            already_treated = (
                len(
                    self.db.query(Community)
                    .filter(Community.entities_ids == community)
                    .all()
                )
                > 0
            )

            if not already_treated:

                prompt, system_prompt = self.get_context_for_community(
                    ids=community,
                    overall=overall,
                    language=language,
                    community_as_entity=community_as_entity,
                )
                communities_to_process.append(community)
                prompts_to_process.append(prompt)
                system_prompts_to_process.append(system_prompt)

        outputs = self.agent.multiple_predict(
            prompts_to_process, system_prompts_to_process
        )
        tokens = 0
        taille_batch = 500
        outputs = None
        for i in range(0, len(prompts_to_process), taille_batch):
            results = self.agent.multiple_predict(prompts=prompts_to_process[i:i + taille_batch],
                                            system_prompts=system_prompts_to_process[i:i + taille_batch])
            if outputs is None:
                outputs = results
            else:
                outputs["texts"].append(results["texts"])
                outputs["nb_input_tokens"]+=np.sum(results["nb_input_tokens"])
                outputs["nb_output_tokens"]+=np.sum(results["nb_output_tokens"])
                outputs["impacts"][0]+=results["impacts"][0]
                outputs["impacts"][1]+=results["impacts"][1]
                outputs["energy"][0]+=results["energy"][0]
                outputs["energy"][1]+=results["energy"][1]
        llm_outputs = outputs["texts"]
        input_tokens = np.sum(outputs["nb_input_tokens"])
        output_tokens = np.sum(outputs["nb_output_tokens"])

        new_communities = self.clean_outputs(
            llm_outputs, communities_to_process, deep_level
        )

        for new_community in new_communities:
            self.db.add_instance(new_community)

        communities_tokens = Tokens(
            title="communities",
            embedding_tokens=0,
            input_tokens=int(input_tokens),
            output_tokens=int(output_tokens),
        )
        self.db.add_instance(communities_tokens)

        print("Processing communities - âœ…")

    def _handle_single_community(self, output):
        try:
            data = json.loads(output)
            title = data.get("title", "")
            description = data.get("description", "")

            return title, description
        except json.JSONDecodeError:
            title_match = re.search(r'"title"\s*:\s*"([^"]*)"', output)
            description_match = re.search(r'"description"\s*:\s*"([^"]*)"', output)

            title = title_match.group(1) if title_match else None
            description = description_match.group(1) if description_match else None

            return title, description

    def clean_outputs(
        self, outputs: list[str], communities_to_process, deep_level
    ) -> list[Community]:

        new_communities = []
        for output, community in zip(outputs, communities_to_process):
            title, description = self._handle_single_community(output)
            if title and description is not None:
                new_community = Community(
                    title=title,
                    description=description,
                    entities_ids=community,
                    hierarchical_level=deep_level,
                )
                new_communities.append(new_community)

        return new_communities
